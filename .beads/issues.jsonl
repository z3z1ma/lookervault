{"id":"lookervault-0me","title":"Cache resolved folder hierarchy in extraction session metadata for resume capability","description":"Cache the resolved folder hierarchy (folder_ids after recursive expansion) in extraction session metadata. This allows resume operations to skip folder hierarchy re-resolution. Currently hierarchy is re-resolved on every extraction. Small memory overhead (~10KB per 1000 folders) for significant resume speedup.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T10:59:18.1774-07:00","updated_at":"2025-12-14T11:24:42.551722-07:00","closed_at":"2025-12-14T11:24:42.551722-07:00","dependencies":[{"issue_id":"lookervault-0me","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:18.178155-07:00","created_by":"daemon"}]}
{"id":"lookervault-73h","title":"Add folder-level filtering for extract and restore operations","description":"Add ability to target specific Looker folders for extraction and restoration operations.\n\nCurrent behavior:\n- Extract/restore operates on entire content types (all dashboards, all looks, etc.)\n- No way to selectively backup/restore content within specific folders\n\nDesired behavior:\n- Extract: --folder-id flag to extract only content within a specific folder (and optionally subfolders with --recursive)\n- Restore: --folder-id flag to restore only content that belonged to specific folders\n- Useful for: selective backups, team-specific workflows, testing on smaller subsets, partial restorations\n\nImplementation considerations:\n- Looker API supports folder filtering on content endpoints\n- May need to handle folder hierarchy (parent/child relationships)\n- Should work with existing parallel extraction/restoration architecture\n- Consider whether to extract folder metadata separately or inline with content","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-13T23:08:37.681778-07:00","updated_at":"2025-12-14T10:52:21.136309-07:00","closed_at":"2025-12-14T10:52:21.136309-07:00"}
{"id":"lookervault-7p7","title":"Add indexed folder_id column to content_items table for faster SQL filtering","description":"Add a dedicated folder_id column to the content_items table with a partial index for faster SQL-based folder filtering. Currently folder_id is stored in the serialized content_data BLOB requiring Python-side deserialization for filtering. Benefits: 10-100x faster folder-filtered queries, enables SQL WHERE clauses, reduces memory usage. Requires schema migration.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T10:59:16.111871-07:00","updated_at":"2025-12-14T11:39:52.135358-07:00","closed_at":"2025-12-14T11:39:52.135358-07:00","dependencies":[{"issue_id":"lookervault-7p7","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:16.112838-07:00","created_by":"daemon"}]}
{"id":"lookervault-83w","title":"Implement dashboard sub-resource restoration (elements, filters, layouts)","description":"","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-13T21:59:46.610527-07:00","updated_at":"2025-12-13T22:08:35.483289-07:00","closed_at":"2025-12-13T22:08:35.483289-07:00"}
{"id":"lookervault-dil","title":"Replace multi-folder in-memory filtering with parallel SDK calls (critical perf optimization)","description":"CRITICAL PERFORMANCE: Replaced multi-folder in-memory filtering with parallel SDK API calls for 10-100x performance improvement.\n\n**COMPLETED** (Phase 1 \u0026 2):\n- ✅ MultiFolderOffsetCoordinator class with round-robin folder selection\n- ✅ Per-folder offset tracking with thread-safe coordination\n- ✅ Modified _parallel_fetch_worker() to support multi-folder coordinator\n- ✅ Updated _extract_parallel() to create MultiFolderOffsetCoordinator when appropriate\n- ✅ Removed in-memory filtering code (SDK handles filtering)\n- ✅ Updated CLAUDE.md with optimization details\n\n**PENDING** (Phase 3 - Testing):\n- ⏳ Unit tests for MultiFolderOffsetCoordinator\n- ⏳ Integration tests for multi-folder extraction\n- ⏳ Performance benchmarks\n\n**Performance**: 3 folders × 1k dashboards: 20s → 2s (10x), 10 folders × 500 dashboards: 38s → 3s (12x)\n\n**Design**: See history/multi-folder-sdk-optimization-plan.md for detailed implementation design.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T10:59:21.571339-07:00","updated_at":"2025-12-14T11:17:09.864001-07:00","closed_at":"2025-12-14T11:17:09.864001-07:00","dependencies":[{"issue_id":"lookervault-dil","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:21.571947-07:00","created_by":"daemon"}]}
{"id":"lookervault-e7b","title":"Add folder_ids parsing and validation to extract.py command module","description":"CRITICAL: CLI flags --folder-ids and --recursive are defined in main.py but not implemented in cli/commands/extract.py. Need to: (1) Parse folder_ids from comma-separated string, (2) Validate content types support folder filtering (error on USER, GROUP, ROLE, etc.), (3) Pass folder_ids set to ExtractionConfig, (4) Handle recursive flag. Without this, the feature is non-functional from CLI.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-14T10:59:19.316861-07:00","updated_at":"2025-12-14T11:23:03.166867-07:00","closed_at":"2025-12-14T11:23:03.166867-07:00","dependencies":[{"issue_id":"lookervault-e7b","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:19.317464-07:00","created_by":"daemon"}]}
{"id":"lookervault-e8c","title":"Verify and document Looker SDK folder filtering support across all content types","description":"Verify which Looker SDK methods support folder_id filtering and document the findings. Currently assuming search_dashboards and search_looks support it. Need to check: search_boards, all other content types. Document in CLAUDE.md or create reference guide. This informs optimization decisions.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T10:59:17.122245-07:00","updated_at":"2025-12-14T11:25:15.910119-07:00","closed_at":"2025-12-14T11:25:15.910119-07:00","dependencies":[{"issue_id":"lookervault-e8c","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:17.122892-07:00","created_by":"daemon"}]}
{"id":"lookervault-iop","title":"Add folder_ids parsing and validation to restore.py command modules","description":"CRITICAL: CLI flags --folder-ids and --recursive are defined in main.py but not implemented in cli/commands/restore.py and restore_all.py. Need to: (1) Parse folder_ids from comma-separated string, (2) Validate content types support folder filtering, (3) Resolve hierarchy if recursive, (4) Pass folder_ids list to RestorationConfig. Without this, the feature is non-functional from CLI.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-14T10:59:20.402644-07:00","updated_at":"2025-12-14T11:25:15.034211-07:00","closed_at":"2025-12-14T11:25:15.034211-07:00","dependencies":[{"issue_id":"lookervault-iop","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:20.40331-07:00","created_by":"daemon"}]}
{"id":"lookervault-yos","title":"Make all SQLite write operations idempotent (upsert)","description":"## Problem\n\nCurrently when running multiple extractions, the system appends content instead of performing upsert operations. This breaks the most common workflow: pull snapshot → run partial extract to update → upload updated snapshot.\n\n## Current State Analysis\n\n**Already Upsert (✅)**:\n- save_content(): Uses INSERT ... ON CONFLICT(id) DO UPDATE SET\n- save_id_mapping(): Uses INSERT ... ON CONFLICT(...) DO UPDATE SET\n\n**Plain INSERT (❌ - Needs Fix)**:\n- save_checkpoint(): Lines 601-655\n- create_session(): Lines 758-792\n- save_dead_letter_item(): Lines 1158-1214\n- save_restoration_checkpoint(): Lines 1612-1666\n- create_restoration_session(): Lines 1769-1822\n\n## Impact\n\nWithout upsert operations:\n- Running extract twice creates duplicate checkpoint entries or fails on PK violation\n- Resuming with same session_id fails instead of updating existing session\n- DLQ items can be duplicated if retry logic re-saves same failure\n- Cannot safely re-run partial extractions to update snapshots\n\n## Requirements\n\nALL write operations must be idempotent:\n1. Running operation twice with same data = same final state\n2. No errors on re-run (no PK violations)\n3. Updates existing records instead of creating duplicates\n4. Safe for the workflow: pull → partial extract → upload\n\n## Acceptance Criteria\n\n- [ ] save_checkpoint() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] create_session() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] save_dead_letter_item() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] save_restoration_checkpoint() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] create_restoration_session() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] All operations tested with duplicate calls (verify idempotency)\n- [ ] No database schema changes required (current PKs/constraints sufficient)","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-14T12:15:10.356229-07:00","updated_at":"2025-12-14T13:00:28.094881-07:00","closed_at":"2025-12-14T13:00:28.094881-07:00"}

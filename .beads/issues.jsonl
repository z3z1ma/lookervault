{"id":"lookervault-02l","title":"Remove or implement TODO comment: dependency validation in restore.py","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:54:13.410471-07:00","updated_at":"2025-12-31T22:22:26.159265-07:00","closed_at":"2025-12-31T22:22:26.159265-07:00","close_reason":"Dependency validation already fully implemented in restore.py (lines 473-507). The RestorationValidator.validate_dependencies() method was implemented in commit 03d63d9 and issue lookervault-hu3 was closed. No TODO comment exists to remove - this issue was created after the implementation was complete."}
{"id":"lookervault-04w","title":"Add type hints to _sdk_object_to_dict - primitive obsession with dict[str, Any]","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:44.297892-07:00","updated_at":"2025-12-31T23:53:56.313552-07:00","closed_at":"2025-12-31T23:53:56.313552-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-07i","title":"Replace typer[all] with typer (remove shellingham)","description":"## Problem\n\nProject uses `typer[all]\u003e=0.9.0` which installs shellingham for shell auto-completion, but completion is explicitly DISABLED:\n- Specified: `typer[all]\u003e=0.9.0` in pyproject.toml (brings in shellingham)\n- CLI config: `add_completion=False` in cli/main.py line 15\n- shellingham usage: Zero (only used for completion feature)\n\n## Evidence\n\n```python\n# cli/main.py line 13-16\napp = typer.Typer(\n    help=\"LookerVault - Backup and restore tool for Looker instances\",\n    add_completion=False,  # ← Completion disabled\\!\n    no_args_is_help=True,\n)\n```\n\n## Impact\n\n- Unnecessary shellingham dependency (~20KB)\n- Misleading dependency spec (suggests completion available when disabled)\n- No value provided (completion feature disabled)\n\n## Solution\n\nReplace `typer[all]` with plain `typer`:\n```bash\nuv remove typer\nuv add 'typer\u003e=0.9.0'  # Without [all] extra\n```\n\n## What Changes\n\n**Removed**: shellingham (shell detection for completion)\n**Kept**: typer, click, rich, typing-extensions\n\n## Notes\n\n- Rich is already a direct dependency, so no impact\n- If completion needed later, change back to typer[all]","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-14T20:55:52.501776-07:00","updated_at":"2025-12-31T23:14:19.147623-07:00","closed_at":"2025-12-31T23:14:19.147623-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-0b3","title":"Consider adding additional dev dependencies for better development experience","description":"## Problem\n\nDev dependencies are minimal. Consider adding tools that improve development workflow:\n\n## Current Dev Dependencies\n\n```toml\n[dependency-groups]\ndev = [\n    \"ty\u003e=0.0.1a34\",\n    \"pytest\u003e=7.4.0\",\n    \"pytest-cov\u003e=4.1.0\",\n    \"pytest-mock\u003e=3.12.0\",\n    \"ruff\u003e=0.8.0\",\n]\n```\n\n## Suggested Additional Dev Tools\n\n### Testing Enhancements\n```toml\n\"pytest-xdist\u003e=3.5.0\",        # Parallel test execution\n\"pytest-timeout\u003e=2.2.0\",      # Timeout protection for long tests\n\"pytest-sugar\u003e=1.0.0\",        # Better pytest output\n\"pytest-asyncio\u003e=0.23.0\",     # If async tests needed\n\"faker\u003e=22.0.0\",              # Generate test data\n```\n\n### Code Quality\n```toml\n\"pre-commit\u003e=3.6.0\",          # Pre-commit hook management\n\"interrogate\u003e=1.5.0\",         # Docstring coverage checker\n\"vulture\u003e=2.11\",              # Find dead code\n\"bandit\u003e=1.7.6\",              # Security linting (alternative to ruff's S rules)\n```\n\n### Development Tools\n```toml\n\"ipython\u003e=8.20.0\",            # Better REPL\n\"ipdb\u003e=0.13.13\",              # Better debugger\n\"rich-cli\u003e=1.8.0\",            # Rich formatting in terminal\n```\n\n### Documentation\n```toml\n\"mkdocs\u003e=1.5.3\",              # Documentation generator\n\"mkdocs-material\u003e=9.5.0\",     # Material theme for docs\n\"mkdocstrings[python]\u003e=0.24\", # Auto-generate API docs from docstrings\n```\n\n## Recommendation\n\nAdd incrementally based on needs:\n1. **High value**: pytest-xdist (parallel tests), pre-commit (automation)\n2. **Medium value**: ipython/ipdb (debugging), pytest-sugar (better output)\n3. **Lower priority**: Documentation tools (if publishing docs)\n\n## Priority\n\nLow (P3) - Nice to have, not essential for current development\n\n## Note\n\nSome functionality already covered:\n- ruff handles many code quality checks (replaces bandit, isort, etc.)\n- ty handles type checking\n- Current setup is lean and functional","status":"open","priority":3,"issue_type":"chore","created_at":"2025-12-14T20:42:56.952634-07:00","updated_at":"2025-12-14T20:42:56.952634-07:00"}
{"id":"lookervault-0me","title":"Cache resolved folder hierarchy in extraction session metadata for resume capability","description":"Cache the resolved folder hierarchy (folder_ids after recursive expansion) in extraction session metadata. This allows resume operations to skip folder hierarchy re-resolution. Currently hierarchy is re-resolved on every extraction. Small memory overhead (~10KB per 1000 folders) for significant resume speedup.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T10:59:18.1774-07:00","updated_at":"2025-12-14T11:24:42.551722-07:00","closed_at":"2025-12-14T11:24:42.551722-07:00","dependencies":[{"issue_id":"lookervault-0me","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:18.178155-07:00","created_by":"daemon","metadata":"{}"}]}
{"id":"lookervault-0qw","title":"Consider replacing pathvalidate with stdlib regex for path sanitization","description":"## Analysis\n\npathvalidate is used for cross-platform path sanitization (Windows reserved names, control characters, length limits).\n\n**Current usage**:\n```python\n# src/lookervault/export/path_utils.py:13\nfrom pathvalidate import Platform, sanitize_filename\n\nsafe_name = sanitize_filename(\n    normalized,\n    platform=Platform.WINDOWS,  # Most restrictive for max compatibility\n    max_len=max_length,\n    replacement_text=\"_\",\n)\n```\n\n**Stdlib alternative**:\nCould replace with custom regex + manual handling:\n```python\nimport re\nimport unicodedata\n\n# Windows invalid chars: \u003c \u003e : \" / \\\\ | ? *\n# Windows reserved names: CON, PRN, AUX, NUL, COM1-9, LPT1-9\ndef sanitize_filename(name: str, max_len: int = 255) -\u003e str:\n    name = unicodedata.normalize(\"NFC\", name)\n    name = re.sub(r'[\u003c\u003e:\"/\\\\|?*]', '_', name)\n    name = re.sub(r'[\\x00-\\x1f]', '', name)  # Control chars\n    # Check reserved names: CON, PRN, AUX, etc.\n    # ... (additional logic needed)\n    return name[:max_len]\n```\n\n## Tradeoff Analysis\n\n**Keep pathvalidate** (recommended):\n✅ Handles edge cases (reserved names, Unicode edge cases, platform differences)\n✅ Battle-tested library (~1M downloads/month)\n✅ Saves ~100 lines of custom logic\n✅ Better Unicode handling than naive regex\n❌ Adds ~50KB dependency\n\n**Replace with stdlib**:\n✅ No external dependency\n✅ Full control over logic\n❌ Need to reimplement reserved name checks (CON, PRN, AUX, etc.)\n❌ Risk missing edge cases (Unicode normalization, zero-width chars, etc.)\n❌ More maintenance burden (cross-platform testing)\n\n## Recommendation\n\n**KEEP pathvalidate** - the dependency is small and the functionality is complex enough that a custom implementation is likely to have bugs. The library handles:\n- Windows reserved names (CON, PRN, AUX, NUL, COM1-9, LPT1-9)\n- Control characters\n- Unicode edge cases\n- Platform-specific path rules\n- Length truncation with proper UTF-8 handling\n\nOnly replace if dependency count is critical constraint.\n\n## Status\n\nClosing as WONTFIX - dependency provides genuine value.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-14T20:55:27.169465-07:00","updated_at":"2025-12-14T20:55:32.221248-07:00","closed_at":"2025-12-14T20:55:32.221248-07:00"}
{"id":"lookervault-18g","title":"Document upsert behavior for SQLite write operations","description":"CLAUDE.md mentions upsert operations after lookervault-yos fix but README lacks explanation. Add section explaining idempotent operations, ON CONFLICT behavior, and why running extract twice is safe.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:41:33.390635-07:00","updated_at":"2025-12-14T21:27:10.930372-07:00","closed_at":"2025-12-14T21:27:10.930372-07:00"}
{"id":"lookervault-1b6","title":"Update CLAUDE.md to document pack/unpack commands","description":"CLAUDE.md has detailed YAML export/import section but README missing pack/unpack CLI usage. Need to add CLI command examples to Recent Changes or Active Technologies sections showing lookervault pack/unpack usage.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:40:53.270812-07:00","updated_at":"2025-12-14T21:23:22.881386-07:00","closed_at":"2025-12-14T21:23:22.881386-07:00"}
{"id":"lookervault-1jm","title":"Add performance and load tests for parallel extraction and restoration","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T20:44:10.667098-07:00","updated_at":"2025-12-14T20:44:10.667098-07:00"}
{"id":"lookervault-22y","title":"Add docstrings for YamlValidator error categorization","description":"File: src/lookervault/export/validator.py. Methods like _validate_syntax, _validate_schema, _validate_query_structure lack docstrings explaining validation rules and error categories. Add complete docstrings with examples of valid/invalid content.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:00.266125-07:00","updated_at":"2025-12-14T20:41:00.266125-07:00"}
{"id":"lookervault-2io","title":"Remove duplicate unpack command wrapper in main.py - use unpack module directly","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:55:18.580263-07:00","updated_at":"2025-12-31T21:38:47.885412-07:00","closed_at":"2025-12-31T21:38:47.885412-07:00","close_reason":"Completed via parallel sub-agents"}
{"id":"lookervault-2qo","title":"Add test coverage for deserialization and validation modules (restoration path)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:43:14.729058-07:00","updated_at":"2025-12-14T21:45:39.86734-07:00","closed_at":"2025-12-14T21:45:39.86734-07:00"}
{"id":"lookervault-458","title":"Remove unnecessary pass statement in RichProgressTracker.emit_event()","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:56:17.209569-07:00","updated_at":"2025-12-31T22:59:45.239677-07:00","closed_at":"2025-12-31T22:59:45.239677-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-46p","title":"Investigate looker-sdk version discrepancy (specified \u003e=24.0.0, installed 25.20.0)","description":"## Problem\n\nMajor version mismatch between specification and installed version:\n- **Specified**: `looker-sdk\u003e=24.0.0` in pyproject.toml\n- **Installed**: `looker-sdk v25.20.0` (from uv tree)\n- **Gap**: 1 major version ahead of minimum\n\n## Risk Analysis\n\n**Potential Breaking Changes**:\n- looker-sdk 24.x → 25.x may have breaking API changes\n- Code written against v24 API may break with v25 changes\n- API deprecations in v25 might not be compatible with v24 assumptions\n\n**Current Status**:\n- ✅ Code appears to work with v25 (tests passing)\n- ❌ Not explicitly tested against v24 minimum\n- ❌ Unknown if v24 API is actually compatible\n\n## Recommendations\n\n### Option 1: Verify Compatibility (Recommended)\n1. Test with looker-sdk 24.0.0: `uv add looker-sdk==24.0.0`\n2. Run full test suite\n3. If tests pass: Update spec to `\u003e=24.0.0,\u003c26.0.0`\n4. If tests fail: Update minimum to `\u003e=25.0.0`\n\n### Option 2: Update Minimum Version\nIf v24 not needed:\n```toml\n\"looker-sdk\u003e=25.0.0,\u003c26.0.0\"  # Explicit v25 requirement\n```\n\n### Option 3: Pin to Current Version\nMost conservative:\n```toml\n\"looker-sdk\u003e=25.20.0,\u003c26.0.0\"  # Lock to known-working version\n```\n\n## Investigation Steps\n\n1. Check looker-sdk changelog: https://github.com/looker-open-source/sdk-codegen/blob/main/CHANGELOG.md\n2. Search for breaking changes between v24 → v25\n3. Test with minimum version: `uv add looker-sdk==24.0.0 \u0026\u0026 uv run pytest`\n4. Document findings and update dependency spec\n\n## Impact\n\nMedium (P2) - Could cause issues in environments with older looker-sdk versions\n\n## Related\n\nSee bead lookervault-cvw about adding upper bounds to all dependencies","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-14T20:43:28.803037-07:00","updated_at":"2025-12-14T21:45:36.446896-07:00","closed_at":"2025-12-14T21:45:36.446896-07:00"}
{"id":"lookervault-4aq","title":"Document thread-safety patterns in parallel extraction","description":"File: src/lookervault/extraction/parallel_orchestrator.py. Thread-local connections, BEGIN IMMEDIATE transactions, and retry logic well-implemented but lacks explanatory comments. Add inline comments documenting thread-safety guarantees and pitfalls.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:03.855876-07:00","updated_at":"2025-12-14T20:41:03.855876-07:00"}
{"id":"lookervault-4ay","title":"Add error message documentation for common failure scenarios","description":"Troubleshooting section in README.md missing error messages for: checksum validation failures, YAML schema errors, query recreation failures, folder hierarchy resolution errors. Add examples of actual error messages and solutions.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:40:56.735616-07:00","updated_at":"2025-12-14T20:40:56.735616-07:00"}
{"id":"lookervault-4ni","title":"Remove unused Configuration.config_version field (never validated or checked)","description":"## Location\n\nsrc/lookervault/config/models.py:46\n\n## Evidence\n\nField defined as:\n```python\nconfig_version: str = '1.0'\n```\n\nGrep shows it's ONLY defined, never accessed:\n- Not checked during config loading\n- Not validated against expected version\n- No migration logic based on version\n- Not used in any feature logic\n\n## Impact\n\n- Suggests versioning exists when it doesn't\n- No actual version checking or migration support\n- Just adds noise to config model\n\n## Safe to Remove\n\nSince there's no version checking logic, this field serves no purpose. If config versioning is needed in future, it should be implemented with actual validation logic, not just a static field.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:31.159694-07:00","updated_at":"2025-12-31T22:59:14.222381-07:00","closed_at":"2025-12-31T22:59:14.222381-07:00","close_reason":"Removed unused config_version field from Configuration model (already done in commit 6b500ec)"}
{"id":"lookervault-4u8","title":"Add GitHub Actions CI/CD workflow for automated testing and quality checks","description":"## Problem\n\nNo GitHub Actions workflows configured. No automated CI/CD pipeline for:\n- Running tests on PRs\n- Enforcing code quality checks\n- Publishing releases\n- Preventing broken code from merging\n\n## Current State\n\n- ❌ No .github/workflows/ directory\n- ❌ No CI pipeline\n- ❌ No automated test runs\n- ✅ copilot-instructions.md exists in .github/\n\n## Recommendation\n\nAdd GitHub Actions workflows:\n\n### 1. ci.yml - Main CI Pipeline\nRun on every PR and push to main:\n- Setup Python 3.13 with uv\n- Install dependencies (uv sync)\n- Run ruff format --check (fail if not formatted)\n- Run ruff check (fail on lint errors)\n- Run ty check (fail on type errors)\n- Run pytest with coverage\n- Upload coverage to codecov/coveralls\n\n### 2. release.yml - Release Automation (Optional)\nTriggered on version tags (v*):\n- Build Python package (uv build)\n- Publish to PyPI (optional, for future public release)\n\n## Benefits\n\n- Automated testing prevents broken code from merging\n- Enforces code quality standards\n- Provides visibility into test coverage\n- Catches issues before they reach main branch\n- Standard practice for open-source Python projects\n\n## Implementation Priority\n\nHigh (P1) - Essential for maintaining code quality as project grows\n\n## Example Workflow\n\n```yaml\nname: CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: astral-sh/setup-uv@v5\n        with:\n          python-version: \"3.13\"\n      - run: uv sync\n      - run: uvx ruff format --check\n      - run: uvx ruff check\n      - run: uvx ty check\n      - run: uv run pytest --cov\n```","status":"closed","priority":1,"issue_type":"chore","created_at":"2025-12-14T20:41:20.396574-07:00","updated_at":"2025-12-14T21:09:45.583017-07:00","closed_at":"2025-12-14T21:09:45.583017-07:00"}
{"id":"lookervault-4uc","title":"Document GCS snapshot configuration requirements in README","description":"README.md configuration section lacks GCS snapshot setup instructions. Need to add section explaining bucket creation, service account setup, credentials configuration. Point to specs/005 for detailed setup.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:40:55.574923-07:00","updated_at":"2025-12-14T21:23:49.913854-07:00","closed_at":"2025-12-14T21:23:49.913854-07:00"}
{"id":"lookervault-55u","title":"Improve test assertion quality and error message clarity","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:46:08.243698-07:00","updated_at":"2025-12-14T20:46:08.243698-07:00"}
{"id":"lookervault-5cp","title":"Remove unused method parameter 'task' in ContentPacker._process_file()","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:42.970441-07:00","updated_at":"2025-12-31T22:47:13.246021-07:00","closed_at":"2025-12-31T22:47:13.246021-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-5x1","title":"Add test fixtures and factories for reusable test data generation","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:45:40.851382-07:00","updated_at":"2025-12-14T20:45:40.851382-07:00"}
{"id":"lookervault-66s","title":"Simplify complex boolean conditions in restore_all.py and extractor.py","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:45.521793-07:00","updated_at":"2025-12-31T23:39:19.311069-07:00","closed_at":"2025-12-31T23:39:19.311069-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-689","title":"Document snapshot retention policy configuration options","description":"README.md and specs/005 lack examples of retention policy configuration. Need to document max_age_days, max_count, keep_daily/weekly/monthly patterns. Add examples in config.toml format with explanations.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:41:30.911437-07:00","updated_at":"2025-12-14T21:24:36.044663-07:00","closed_at":"2025-12-14T21:24:36.044663-07:00"}
{"id":"lookervault-6c2","title":"Add examples section to OffsetCoordinator docstrings","description":"Files: src/lookervault/extraction/offset_coordinator.py and multi_folder_coordinator.py. Class docstrings lack usage examples. Add Examples sections showing worker coordination patterns and typical usage scenarios.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:40:54.486985-07:00","updated_at":"2025-12-14T20:40:54.486985-07:00"}
{"id":"lookervault-6ii","title":"Add missing docstring for FolderHierarchyResolver methods","description":"File: src/lookervault/folder/hierarchy.py. Methods like get_all_descendant_ids, _build_parent_child_map, _load_folder_cache lack docstrings. Add complete method documentation with Args, Returns, Raises, Examples.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:29.6899-07:00","updated_at":"2026-01-01T00:06:23.094039-07:00","closed_at":"2026-01-01T00:06:23.094039-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-6q9","title":"Remove unused dependency: pyyaml","description":"## Problem\n\nPyYAML is listed in project.dependencies but is NEVER imported anywhere in the codebase:\n- Specified: `pyyaml\u003e=6.0.3` in pyproject.toml line 16\n- Actual usage: Zero imports (verified with grep -r \"import yaml\")\n- Alternative: ruamel-yaml is used for ALL YAML operations (export/import module)\n\n## Evidence\n\n```bash\n# No PyYAML imports found\n$ grep -r \"^import yaml|^from yaml\" src/\n# (empty)\n\n# Only ruamel.yaml is used\n$ grep -r \"ruamel\" src/\nsrc/lookervault/export/yaml_serializer.py:from ruamel.yaml import YAML\nsrc/lookervault/export/validator.py:from ruamel.yaml import YAML\n```\n\n## Impact\n\n- Unnecessary dependency adds ~200KB to installation\n- Confuses developers (two YAML libraries?)\n- No value provided (100% dead code)\n\n## Solution\n\nRemove from pyproject.toml:\n```bash\nuv remove pyyaml\n```\n\n## References\n\n- ruamel-yaml handles all YAML needs (export/import, validation)\n- No migration needed (pyyaml never used)","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-14T20:53:56.656065-07:00","updated_at":"2025-12-31T22:59:45.23629-07:00","closed_at":"2025-12-31T22:59:45.23629-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-73h","title":"Add folder-level filtering for extract and restore operations","description":"Add ability to target specific Looker folders for extraction and restoration operations.\n\nCurrent behavior:\n- Extract/restore operates on entire content types (all dashboards, all looks, etc.)\n- No way to selectively backup/restore content within specific folders\n\nDesired behavior:\n- Extract: --folder-id flag to extract only content within a specific folder (and optionally subfolders with --recursive)\n- Restore: --folder-id flag to restore only content that belonged to specific folders\n- Useful for: selective backups, team-specific workflows, testing on smaller subsets, partial restorations\n\nImplementation considerations:\n- Looker API supports folder filtering on content endpoints\n- May need to handle folder hierarchy (parent/child relationships)\n- Should work with existing parallel extraction/restoration architecture\n- Consider whether to extract folder metadata separately or inline with content","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-13T23:08:37.681778-07:00","updated_at":"2025-12-14T10:52:21.136309-07:00","closed_at":"2025-12-14T10:52:21.136309-07:00"}
{"id":"lookervault-74y","title":"Document YAML export/import workflow in README.md","description":"README.md missing documentation for pack/unpack commands. Need to add section explaining YAML export workflow: extract → unpack → modify → pack → restore. Include examples of bulk modifications (sed/grep/Python scripts).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:40:47.461412-07:00","updated_at":"2025-12-14T21:10:25.350191-07:00","closed_at":"2025-12-14T21:10:25.350191-07:00"}
{"id":"lookervault-7dl","title":"Remove unused --compare-live flag from verify command (not implemented)","description":"## Location\n\nsrc/lookervault/cli/commands/verify.py:119-122\n\n## Evidence\n\nDefined as CLI flag (main.py line 194-196) and passed to verify.run(), but implementation is stubbed:\n\n```python\nif compare_live:\n    console.print('\\n[cyan]Comparing with live Looker instance...[/cyan]')\n    # This would require loading config and comparing\n    console.print('[yellow]Live comparison not yet implemented[/yellow]')\n```\n\n## Impact\n\n- Misleads users into thinking this feature works\n- No actual functionality behind the flag\n- Would require loading Looker config and fetching current content to compare\n\n## Options\n\n1. Remove the flag entirely (recommended for cleanup)\n2. Implement the feature (requires significant work: load config, fetch live content, compare)\n3. Hide the flag or mark as experimental\n\nRecommend option 1 since this is a cleanup task.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:53:25.787886-07:00","updated_at":"2025-12-31T23:26:04.815457-07:00","closed_at":"2025-12-31T23:26:04.815457-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-7p7","title":"Add indexed folder_id column to content_items table for faster SQL filtering","description":"Add a dedicated folder_id column to the content_items table with a partial index for faster SQL-based folder filtering. Currently folder_id is stored in the serialized content_data BLOB requiring Python-side deserialization for filtering. Benefits: 10-100x faster folder-filtered queries, enables SQL WHERE clauses, reduces memory usage. Requires schema migration.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T10:59:16.111871-07:00","updated_at":"2025-12-14T11:39:52.135358-07:00","closed_at":"2025-12-14T11:39:52.135358-07:00","dependencies":[{"issue_id":"lookervault-7p7","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:16.112838-07:00","created_by":"daemon","metadata":"{}"}]}
{"id":"lookervault-7pb","title":"Remove unused --folder filter from list command (not implemented, requires deserialization)","description":"## Location\n\nsrc/lookervault/cli/commands/list.py:94-99\n\n## Evidence\n\nFlag defined in CLI (main.py line 227-229) and passed to list.run(), but implementation is skipped:\n\n```python\nif folder:\n    # Note: folder filtering would require deserializing content_data\n    # For now, we skip this filter as it requires full content access\n    logger.warning(\n        'Folder filtering not yet implemented (requires content deserialization)'\n    )\n```\n\n## Impact\n\n- Flag is accepted but does nothing (silently ignored with warning in logs)\n- Misleads users into thinking folder filtering works\n- Would require deserializing BLOB content to extract folder information\n\n## Why Not Implement\n\nFolder information is already stored in folder_id column (added in schema v2), so this could be implemented. However:\n- If nobody has complained, feature may not be needed\n- Adds query complexity\n- Better to remove unused flag than implement unneeded feature\n\n## Safe to Remove\n\nThe warning shows this was never implemented. Remove the CLI flag since folder_id column exists for direct folder filtering if needed.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:53:29.012593-07:00","updated_at":"2025-12-31T23:39:19.315313-07:00","closed_at":"2025-12-31T23:39:19.315313-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-7sx","title":"Remove unused exception classes: IDMappingError and ConnectionError","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:15.858762-07:00","updated_at":"2025-12-31T23:14:19.145178-07:00","closed_at":"2025-12-31T23:14:19.145178-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-83n","title":"Add test coverage for Looker API client error handling and retry logic","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:43:41.22062-07:00","updated_at":"2025-12-14T22:17:07.330124-07:00","closed_at":"2025-12-14T22:17:07.330124-07:00"}
{"id":"lookervault-83w","title":"Implement dashboard sub-resource restoration (elements, filters, layouts)","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-13T21:59:46.610527-07:00","updated_at":"2025-12-13T22:08:35.483289-07:00","closed_at":"2025-12-13T22:08:35.483289-07:00"}
{"id":"lookervault-8nl","title":"Refactor repository.py - God class with 2079 lines and 80+ methods","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T20:41:38.205386-07:00","updated_at":"2025-12-14T20:41:38.205386-07:00"}
{"id":"lookervault-8p1","title":"Consider removing base exception class LookerVaultError if never caught directly","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:55:44.814547-07:00","updated_at":"2025-12-31T23:50:56.1651-07:00","closed_at":"2025-12-31T23:50:56.1651-07:00","close_reason":"Kept LookerVaultError - provides documentation value and future flexibility with minimal cost"}
{"id":"lookervault-8qh","title":"Remove unused RestorationConfig fields: skip_if_modified, date_range, content_ids, source_instance","description":"## Evidence of Non-Use\n\nRestorationConfig has 4 fields that are defined but never actually used in restoration logic:\n\n**1. skip_if_modified** (lines 238-240):\n- Defined in config, passed through CLI\n- Only mentioned in comments (line 196, 241)\n- Never checked in actual restoration code (parallel_orchestrator.py, restorer.py)\n- Would require comparing destination timestamps with backup timestamps\n\n**2. date_range** (line 252-253):\n- Defined but never accessed anywhere\n- No filtering logic based on date ranges in restoration code\n- Not passed to repository queries\n\n**3. content_ids** (line 246-247):\n- Field defined but never used for filtering\n- Repository get_content_ids() method exists but doesn't take filter parameter\n- Filtering is done by content_type only, not by specific IDs\n\n**4. source_instance** (line 257-258):\n- Defined and stored in restoration_sessions table\n- Only used for display in status commands (restore.py lines 1794, 1874, 1900)\n- Never used for actual ID mapping or cross-instance logic\n- id_mapper exists separately, doesn't use config.source_instance\n\n## Impact\n\nVestigial fields from planned features that were never implemented:\n- Misleads users into thinking these features work\n- Adds unnecessary validation complexity\n- Takes up database columns (source_instance in restoration_sessions)\n\n## Safe to Remove\n\nThese are placeholder fields for features that were planned but never implemented.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:53:24.632469-07:00","updated_at":"2025-12-31T23:39:19.305822-07:00","closed_at":"2025-12-31T23:39:19.305822-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-8sj","title":"Replace typer[all] with typer (remove shellingham)","description":"## Problem\n\nProject uses `typer[all]\u003e=0.9.0` which installs shellingham for shell auto-completion, but completion is explicitly DISABLED:\n- Specified: `typer[all]\u003e=0.9.0` in pyproject.toml (brings in shellingham)\n- CLI config: `add_completion=False` in cli/main.py line 15\n- shellingham usage: Zero (only used for completion feature)\n\n## Evidence\n\n```python\n# cli/main.py line 13-16\napp = typer.Typer(\n    help=\"LookerVault - Backup and restore tool for Looker instances\",\n    add_completion=False,  # ← Completion disabled\\!\n    no_args_is_help=True,\n)\n```\n\n```bash\n$ uv tree | grep typer\n├── typer v0.20.0\n│   ├── click v8.3.1\n│   ├── rich v14.2.0 (already required)\n│   ├── shellingham v1.5.4  # ← Only for completion\n│   └── typing-extensions v4.15.0\n```\n\n## Impact\n\n- Unnecessary shellingham dependency (~20KB)\n- Misleading dependency spec (suggests completion available when disabled)\n- No value provided (completion feature disabled)\n\n## Solution\n\nReplace `typer[all]` with plain `typer`:\n```bash\nuv remove typer\nuv add 'typer\u003e=0.9.0'  # Without [all] extra\n```\n\n## What Changes\n\n**Removed**: shellingham (shell detection for completion)\n**Kept**: typer, click, rich, typing-extensions\n\n## Notes\n\n- Rich is already a direct dependency, so no impact\n- If completion needed later, change back to typer[all]","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-14T20:54:27.03948-07:00","updated_at":"2025-12-31T23:14:19.149785-07:00","closed_at":"2025-12-31T23:14:19.149785-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-98f","title":"Review and potentially tighten Python version requirement (currently \u003e=3.13)","description":"## Problem\n\nProject requires Python \u003e=3.13 with no upper bound. Python 3.13 is very recent (released Oct 2024):\n\n**Considerations:**\n1. **Adoption**: Python 3.13 adoption is still low in enterprises\n2. **Testing**: Only testing against 3.13, not 3.14+ when available\n3. **Compatibility**: May work on future Python versions without testing\n\n## Current Configuration\n\n```toml\n[project]\nrequires-python = \"\u003e=3.13\"\n\n[tool.ruff]\ntarget-version = \"py313\"\n\n[tool.ty.environment]\npython-version = \"3.13\"\n```\n\n.python-version: `3.13`\n\n## Options\n\n### Option 1: Keep as-is (\u003e=3.13)\n- ✅ Forward compatible by default\n- ❌ No guarantees for Python 3.14+\n- Recommendation: Add Python 3.14 testing when available\n\n### Option 2: Lock to 3.13 specifically\n```toml\nrequires-python = \"==3.13.*\"\n```\n- ✅ Explicit about tested version\n- ❌ Prevents use on Python 3.14\n- Use case: If using 3.13-specific features\n\n### Option 3: Semver range\n```toml\nrequires-python = \"\u003e=3.13,\u003c3.15\"\n```\n- ✅ Allows patch/minor within 3.13-3.14\n- ✅ Prevents untested major versions\n- Recommended for stability\n\n## Questions\n\n1. Does the code use Python 3.13-specific features? (PEP 701, 702, 709, etc.)\n2. Should we support Python 3.12 for wider compatibility?\n3. Will CI test against multiple Python versions?\n\n## Recommendation\n\n**If using 3.13-specific features**: Keep \u003e=3.13\n**If no specific features used**: Consider supporting 3.12+ for wider adoption\n\n## Priority\n\nLow (P3) - Current config works, this is about future planning","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-14T20:43:12.450333-07:00","updated_at":"2025-12-31T23:53:56.317354-07:00","closed_at":"2025-12-31T23:53:56.317354-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-98t","title":"Remove unused method parameter 'total_items' in ContentUnpacker._check_disk_space()","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:44.065786-07:00","updated_at":"2025-12-31T22:47:13.244218-07:00","closed_at":"2025-12-31T22:47:13.244218-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-9n4","title":"Extract timestamp parsing to shared utility - duplicated across 3 files","description":"## Problem\n\nThe timestamp parsing logic for created_at and updated_at fields is duplicated across 3 files with nearly identical implementation:\n\n**Files with duplication:**\n1. src/lookervault/extraction/parallel_orchestrator.py (lines 778-816)\n2. src/lookervault/extraction/orchestrator.py (lines 447-485)  \n3. Likely in other files as well\n\n**Current implementation** (repeated ~40 lines per file):\n- Handles str (ISO format with 'Z' replacement)\n- Handles datetime objects (pass-through)\n- Handles int/float (Unix timestamps)\n- Includes error handling with detailed logging\n- Near-identical logic for both created_at and updated_at\n\n**Code smell:**\n- 40+ lines of complex type-checking and conversion logic\n- Multiple isinstance() checks with 3+ branches\n- Duplicated across multiple files\n- Hard to maintain - changes require updating 3+ locations\n\n## Simpler Alternative\n\nExtract to shared utility function in lookervault/utils/datetime_parsing.py:\n\n```python\ndef parse_timestamp(\n    timestamp_value: Any, \n    field_name: str,\n    item_id: str | None = None,\n    default: datetime | None = None\n) -\u003e datetime:\n    \"\"\"Parse timestamp from various formats.\n    \n    Handles:\n    - ISO format strings (with or without 'Z')\n    - datetime objects (pass-through)\n    - Unix timestamps (int/float)\n    - Invalid/missing values (returns default or current time)\n    \"\"\"\n    if default is None:\n        default = datetime.now(UTC)\n        \n    if not timestamp_value:\n        return default\n        \n    try:\n        if isinstance(timestamp_value, str):\n            return datetime.fromisoformat(timestamp_value.replace('Z', '+00:00'))\n        elif isinstance(timestamp_value, datetime):\n            return timestamp_value\n        elif isinstance(timestamp_value, (int, float)):\n            return datetime.fromtimestamp(timestamp_value, tz=UTC)\n        else:\n            logger.warning(f\"Unexpected type for {field_name}: {type(timestamp_value).__name__}\")\n            return default\n    except (ValueError, AttributeError, TypeError) as e:\n        logger.warning(f\"Could not parse {field_name}: {timestamp_value} (item: {item_id}): {e}\")\n        return default\n```\n\n**Usage** (reduces 40 lines to 2):\n```python\ncreated_at = parse_timestamp(item_dict.get('created_at'), 'created_at', item_id)\nupdated_at = parse_timestamp(item_dict.get('updated_at'), 'updated_at', item_id)\n```\n\n## Impact\n\n- **Complexity reduction**: 40 lines → 2 lines per usage\n- **Maintainability**: Single source of truth for timestamp parsing\n- **Testability**: Can unit test the utility function once\n- **Consistency**: All files use same parsing logic","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:41:47.898147-07:00","updated_at":"2025-12-14T21:47:46.146425-07:00","closed_at":"2025-12-14T21:47:46.146425-07:00"}
{"id":"lookervault-a2i","title":"Update .gitignore to include common Python and IDE patterns","description":"## Problem\n\n.gitignore is comprehensive but missing some common patterns:\n- Missing .ruff_cache/ (currently tracked)\n- Missing .coverage.* pattern (only has .coverage)\n- Missing common macOS files beyond .DS_Store\n- Missing common editor temporary files\n\n## Current State\n\n✅ Good coverage of:\n- Python bytecode and build artifacts\n- Virtual environments\n- Testing artifacts (.pytest_cache, .coverage, htmlcov)\n- Type checking (.mypy_cache)\n- IDE files (.vscode, .idea)\n- Database files (*.db, *.sqlite*)\n\n## Recommended Additions\n\n```gitignore\n# Ruff cache (currently missing)\n.ruff_cache/\n\n# Coverage details\n.coverage.*\ncoverage.xml\n*.cover\n\n# macOS\n.AppleDouble\n.LSOverride\n._*\n\n# Vim\n*.swp\n*.swo\n*.swn\n*~\n\n# Emacs\n*~\n\\#*\\#\n.\\#*\n\n# Python type stubs\n*.pyi\n\n# Build artifacts\n*.whl\n*.tar.gz\n\n# Environment files\n.env.local\n.env.*.local\n\n# Temporary files\ntmp/\ntemp/\n*.tmp\n```\n\n## Priority\n\nLow (P3) - Current .gitignore is functional, these are nice-to-haves\n\n## Note\n\n.ruff_cache/ directory exists but not in .gitignore (should add to prevent accidental commits)","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-14T20:42:41.616716-07:00","updated_at":"2025-12-31T23:26:04.818232-07:00","closed_at":"2025-12-31T23:26:04.818232-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-ahc","title":"Consolidate duplicate ValidationError classes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:54:14.714272-07:00","updated_at":"2025-12-31T21:38:47.881773-07:00","closed_at":"2025-12-31T21:38:47.881773-07:00","close_reason":"Completed via parallel sub-agents"}
{"id":"lookervault-alj","title":"Remove TODO comment: GCS logging upload in retention.py","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:18.122637-07:00","updated_at":"2025-12-31T23:26:04.809711-07:00","closed_at":"2025-12-31T23:26:04.809711-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-b1p","title":"Document QueryRemappingTable hash-based deduplication algorithm","description":"File: src/lookervault/export/query_remapper.py. SHA-256 hash-based query deduplication and ID remapping logic lacks explanation of algorithm design. Add class docstring explaining hash calculation, collision handling, and remapping table persistence.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:01.426822-07:00","updated_at":"2025-12-14T20:41:01.426822-07:00"}
{"id":"lookervault-bqf","title":"Add CLI usage examples for pack --force mode","description":"pack command has --force flag for deleting missing items but README lacks usage examples. Document when to use --force, what it does, and safety warnings about data loss.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:32.241388-07:00","updated_at":"2025-12-14T20:41:32.241388-07:00"}
{"id":"lookervault-bts","title":"Remove unused variables in test files (3 occurrences)","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:07.187879-07:00","updated_at":"2025-12-31T23:14:19.156322-07:00","closed_at":"2025-12-31T23:14:19.156322-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-bw6","title":"Simplify convoluted logic: Extract duplicate timestamp parsing to shared utility function","description":"## Problem\n\nThe timestamp parsing logic for created_at and updated_at fields is duplicated across 3 files with nearly identical implementation:\n\n**Files with duplication:**\n1. /src/lookervault/extraction/parallel_orchestrator.py (lines 778-816)\n2. /src/lookervault/extraction/orchestrator.py (lines 447-485)  \n3. Likely in other files as well\n\n**Current implementation** (repeated ~40 lines per file):\n- Handles str (ISO format with 'Z' replacement)\n- Handles datetime objects (pass-through)\n- Handles int/float (Unix timestamps)\n- Includes error handling with detailed logging\n- Near-identical logic for both created_at and updated_at\n\n**Code smell:**\n- 40+ lines of complex type-checking and conversion logic\n- Multiple isinstance() checks with 3+ branches\n- Duplicated across multiple files\n- Hard to maintain - changes require updating 3+ locations\n\n## Simpler Alternative\n\nExtract to shared utility function:\n\n```python\n# lookervault/utils/datetime_parsing.py (or similar)\ndef parse_timestamp(\n    timestamp_value: Any, \n    field_name: str,\n    item_id: str | None = None,\n    default: datetime | None = None\n) -\u003e datetime:\n    \"\"\"Parse timestamp from various formats.\n    \n    Handles:\n    - ISO format strings (with or without 'Z')\n    - datetime objects (pass-through)\n    - Unix timestamps (int/float)\n    - Invalid/missing values (returns default or current time)\n    \"\"\"\n    if default is None:\n        default = datetime.now(UTC)\n        \n    if not timestamp_value:\n        return default\n        \n    try:\n        if isinstance(timestamp_value, str):\n            return datetime.fromisoformat(timestamp_value.replace('Z', '+00:00'))\n        elif isinstance(timestamp_value, datetime):\n            return timestamp_value\n        elif isinstance(timestamp_value, (int, float)):\n            return datetime.fromtimestamp(timestamp_value, tz=UTC)\n        else:\n            logger.warning(\n                f\"Unexpected type for {field_name}: {type(timestamp_value).__name__}\"\n            )\n            return default\n    except (ValueError, AttributeError, TypeError) as e:\n        logger.warning(\n            f\"Could not parse {field_name}: {timestamp_value} (item: {item_id}): {e}\"\n        )\n        return default\n```\n\n**Usage** (reduces 40 lines to 2):\n```python\ncreated_at = parse_timestamp(item_dict.get('created_at'), 'created_at', item_id)\nupdated_at = parse_timestamp(item_dict.get('updated_at'), 'updated_at', item_id)\n```\n\n## Impact\n\n- **Complexity reduction**: 40 lines → 2 lines per usage\n- **Maintainability**: Single source of truth for timestamp parsing\n- **Testability**: Can unit test the utility function once\n- **Consistency**: All files use same parsing logic\n\n## Priority\n\nLow (P3) - Code quality improvement, not a bug. Existing duplicate code works correctly.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:53:01.002948-07:00","updated_at":"2025-12-14T20:54:03.569267-07:00","closed_at":"2025-12-14T20:54:03.569267-07:00"}
{"id":"lookervault-bwm","title":"Simplify convoluted logic: Complex boolean condition with 4 ANDed negations in restore_all.py","description":"## Problem\n\nThe confirmation prompt logic in restore_all.py (line 383) has a complex boolean condition with 4 ANDed negations:\n\n```python\nif not dry_run and not force and not json_output and not quiet:\n```\n\n**Code smell:**\n- 4 negations (not operators) make logic hard to read\n- Complex boolean algebra requiring mental effort to understand\n- De Morgan's law would help: \"show prompt if NONE of these flags are set\"\n- Easy to make mistakes when adding/modifying conditions\n\n**Current meaning**: Show prompt if ALL of these are false:\n- dry_run is False\n- force is False  \n- json_output is False\n- quiet is False\n\n## Simpler Alternative\n\n**Option 1: Positive condition with helper variable:**\n```python\n# Clearer: show prompt if interactive mode (none of these flags set)\nis_interactive_mode = not any([dry_run, force, json_output, quiet])\n\nif is_interactive_mode:\n    console.print(\"WARNING: Bulk restoration...\")\n    # ... rest of prompt\n```\n\n**Option 2: Early return pattern:**\n```python\n# Skip prompt if ANY non-interactive flag is set\nif dry_run or force or json_output or quiet:\n    # Skip confirmation prompt\n    pass  # or just continue to next section\nelse:\n    # Show interactive confirmation\n    console.print(\"WARNING: Bulk restoration...\")\n    # ... rest of prompt\n```\n\n**Option 3: Extract to function:**\n```python\ndef should_show_confirmation_prompt(\n    dry_run: bool, \n    force: bool, \n    json_output: bool, \n    quiet: bool\n) -\u003e bool:\n    \"\"\"Return True if interactive confirmation should be shown.\"\"\"\n    return not any([dry_run, force, json_output, quiet])\n\nif should_show_confirmation_prompt(dry_run, force, json_output, quiet):\n    console.print(\"WARNING: Bulk restoration...\")\n```\n\n## Impact\n\n- **Readability**: Positive condition is easier to understand than 4 negations\n- **Maintainability**: Using any() makes it easier to add/remove flags\n- **Correctness**: Less likely to make boolean logic errors\n- **Clarity**: Intent (\"interactive mode\") is explicit, not implicit\n\n## Location\n\nFile: src/lookervault/cli/commands/restore_all.py\nLine: 383\n\n## Priority\n\nLow (P3) - Code quality improvement. Current code works correctly but requires extra mental effort to understand.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:55:01.655452-07:00","updated_at":"2025-12-31T22:47:13.241358-07:00","closed_at":"2025-12-31T22:47:13.241358-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-cvw","title":"Add upper version bounds to critical dependencies","description":"## Problem\n\nAll dependencies use only lower bounds (\u003e=), no upper bounds. This can lead to:\n- Breaking changes from major version updates\n- Unexpected API changes\n- Hard-to-debug runtime errors after dependency updates\n- Non-reproducible builds across environments\n\n## Current Dependencies (No Upper Bounds)\n\n```python\n\"google-cloud-storage\u003e=3.7.0\",      # Currently 3.7.0\n\"looker-sdk\u003e=24.0.0\",               # Currently 25.20.0 (1 major version ahead!)\n\"msgspec\u003e=0.20.0\",                  # Currently 0.20.0\n\"pydantic\u003e=2.0.0\",                  # Currently 2.12.5\n\"rich\u003e=14.2.0\",                     # Currently 14.2.0\n\"ruamel-yaml\u003e=0.18.0\",              # Currently 0.18.16\n\"typer[all]\u003e=0.9.0\",                # Currently 0.20.0\n```\n\n## Notable Issues\n\n**looker-sdk**: Specified \u003e=24.0.0 but installed 25.20.0 (major version jump!)\n- Risk: Breaking API changes between 24.x and 25.x\n- Recommendation: Pin or use `\u003e=24.0.0,\u003c26.0.0`\n\n## Recommendations\n\n### Option 1: Semver Upper Bounds (Recommended)\n```python\n\"looker-sdk\u003e=24.0.0,\u003c26.0.0\",          # Allow minor/patch within v24-25\n\"pydantic\u003e=2.0.0,\u003c3.0.0\",              # Major version lock\n\"msgspec\u003e=0.20.0,\u003c1.0.0\",              # Lock to 0.x (pre-1.0)\n```\n\n### Option 2: Use uv.lock Only\nKeep lower bounds but rely on uv.lock for reproducibility.\n- ✅ Simpler dependency specification\n- ❌ Less protection against breaking changes\n- ✅ uv.lock provides exact versions\n\n### Option 3: Specific Version Ranges\n```python\n\"looker-sdk\u003e=24.0.0,\u003c25.21.0\",  # Tighter control\n```\n\n## Priority\n\nMedium (P2) - Not urgent but important for stability\n\n## Decision Needed\n\nWhich approach does the project prefer?\n- Tight version bounds (more safety, more maintenance)\n- Loose bounds + uv.lock (simpler, less maintenance)\n- Hybrid (critical deps bounded, others loose)\n\n## Note\n\nuv.lock already provides exact version pinning for reproducibility. Upper bounds mainly protect against unexpected major version upgrades during `uv sync --upgrade`.","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-14T20:42:16.1216-07:00","updated_at":"2025-12-14T21:43:59.173888-07:00","closed_at":"2025-12-14T21:43:59.173888-07:00"}
{"id":"lookervault-cwg","title":"Add troubleshooting section for YAML validation errors","description":"README.md Troubleshooting section missing YAML-specific errors. Add subsection for: invalid YAML syntax, missing required fields, query structure errors, checksum mismatches. Include actual error messages and fixes.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:41:40.408641-07:00","updated_at":"2025-12-14T21:25:51.776353-07:00","closed_at":"2025-12-14T21:25:51.776353-07:00"}
{"id":"lookervault-d0s","title":"Add edge case tests for extraction and storage modules","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:45:11.040434-07:00","updated_at":"2025-12-14T20:45:11.040434-07:00"}
{"id":"lookervault-dil","title":"Replace multi-folder in-memory filtering with parallel SDK calls (critical perf optimization)","description":"CRITICAL PERFORMANCE: Replaced multi-folder in-memory filtering with parallel SDK API calls for 10-100x performance improvement.\n\n**COMPLETED** (Phase 1 \u0026 2):\n- ✅ MultiFolderOffsetCoordinator class with round-robin folder selection\n- ✅ Per-folder offset tracking with thread-safe coordination\n- ✅ Modified _parallel_fetch_worker() to support multi-folder coordinator\n- ✅ Updated _extract_parallel() to create MultiFolderOffsetCoordinator when appropriate\n- ✅ Removed in-memory filtering code (SDK handles filtering)\n- ✅ Updated CLAUDE.md with optimization details\n\n**PENDING** (Phase 3 - Testing):\n- ⏳ Unit tests for MultiFolderOffsetCoordinator\n- ⏳ Integration tests for multi-folder extraction\n- ⏳ Performance benchmarks\n\n**Performance**: 3 folders × 1k dashboards: 20s → 2s (10x), 10 folders × 500 dashboards: 38s → 3s (12x)\n\n**Design**: See history/multi-folder-sdk-optimization-plan.md for detailed implementation design.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T10:59:21.571339-07:00","updated_at":"2025-12-14T11:17:09.864001-07:00","closed_at":"2025-12-14T11:17:09.864001-07:00","dependencies":[{"issue_id":"lookervault-dil","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:21.571947-07:00","created_by":"daemon","metadata":"{}"}]}
{"id":"lookervault-e7b","title":"Add folder_ids parsing and validation to extract.py command module","description":"CRITICAL: CLI flags --folder-ids and --recursive are defined in main.py but not implemented in cli/commands/extract.py. Need to: (1) Parse folder_ids from comma-separated string, (2) Validate content types support folder filtering (error on USER, GROUP, ROLE, etc.), (3) Pass folder_ids set to ExtractionConfig, (4) Handle recursive flag. Without this, the feature is non-functional from CLI.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-14T10:59:19.316861-07:00","updated_at":"2025-12-14T11:23:03.166867-07:00","closed_at":"2025-12-14T11:23:03.166867-07:00","dependencies":[{"issue_id":"lookervault-e7b","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:19.317464-07:00","created_by":"daemon","metadata":"{}"}]}
{"id":"lookervault-e8c","title":"Verify and document Looker SDK folder filtering support across all content types","description":"Verify which Looker SDK methods support folder_id filtering and document the findings. Currently assuming search_dashboards and search_looks support it. Need to check: search_boards, all other content types. Document in CLAUDE.md or create reference guide. This informs optimization decisions.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T10:59:17.122245-07:00","updated_at":"2025-12-14T11:25:15.910119-07:00","closed_at":"2025-12-14T11:25:15.910119-07:00","dependencies":[{"issue_id":"lookervault-e8c","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:17.122892-07:00","created_by":"daemon","metadata":"{}"}]}
{"id":"lookervault-ed7","title":"Document SubResourceRestorer three-phase restoration strategy","description":"File: src/lookervault/restoration/subresource_restorer.py. Three-phase approach (fetch, categorize, execute) mentioned in module docstring but individual phases lack detailed documentation. Add phase-specific docstrings and examples.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:35.636073-07:00","updated_at":"2025-12-14T20:41:35.636073-07:00"}
{"id":"lookervault-erq","title":"Create architecture diagram for parallel extraction workflow","description":"README.md describes parallel extraction but lacks visual diagram. Create ASCII or Mermaid diagram showing: workers, coordinator, rate limiter, queue, database. Add to docs/ or embed in README.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:37.579988-07:00","updated_at":"2025-12-14T20:41:37.579988-07:00"}
{"id":"lookervault-f21","title":"Add inline comments for multi-folder coordinator algorithm","description":"File: src/lookervault/extraction/multi_folder_coordinator.py. Round-robin folder selection algorithm and lazy offset discovery logic lacks inline comments explaining why design choices were made. Add comments explaining algorithm rationale and edge cases.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:40:52.025106-07:00","updated_at":"2025-12-14T20:40:52.025106-07:00"}
{"id":"lookervault-fd8","title":"Document folder-level filtering commands and flags in README","description":"README.md missing documentation for --folder-ids and --recursive flags. Need to add examples showing folder-scoped extraction/restoration. Document which content types support folder filtering (dashboards/looks only).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:40:50.210557-07:00","updated_at":"2025-12-14T21:09:58.225507-07:00","closed_at":"2025-12-14T21:09:58.225507-07:00"}
{"id":"lookervault-fxd","title":"Simplify convoluted logic: Extract repeated coordinator type checking pattern in _parallel_fetch_worker","description":"## Problem\n\nThe _parallel_fetch_worker() method in parallel_orchestrator.py has a repeated pattern where it checks coordinator type and folder_id for end-of-data handling (lines 586-648). This pattern appears 3 times with nearly identical logic:\n\n**Pattern 1: Empty items check (lines 586-599)**\n```python\nif not items or len(items) == 0:\n    if isinstance(coordinator, MultiFolderOffsetCoordinator) and folder_id:\n        logger.info(f\"Worker {worker_id} hit end-of-data for folder {folder_id}...\")\n        coordinator.mark_folder_complete(folder_id)\n    else:\n        logger.info(f\"Worker {worker_id} hit end-of-data at offset {offset}...\")\n        coordinator.mark_worker_complete()\n        break\n    continue\n```\n\n**Pattern 2: Fewer items than requested (lines 634-648)**\n```python\nif len(items) \u003c limit:\n    if isinstance(coordinator, MultiFolderOffsetCoordinator) and folder_id:\n        logger.info(f\"Worker {worker_id} received {len(items)} \u003c {limit} items for folder {folder_id}...\")\n        coordinator.mark_folder_complete(folder_id)\n    else:\n        logger.info(f\"Worker {worker_id} received {len(items)} \u003c {limit} items...\")\n        coordinator.mark_worker_complete()\n        break\n    continue\n```\n\n**Code smells:**\n- Same isinstance() check repeated multiple times\n- Same branching logic for multi-folder vs single-folder\n- Different log messages but identical control flow\n- Hard to maintain - changes require updating 3+ locations\n\n## Simpler Alternative\n\nExtract to helper method:\n\n```python\ndef _handle_end_of_data(\n    self,\n    coordinator: OffsetCoordinator | MultiFolderOffsetCoordinator,\n    worker_id: int,\n    folder_id: str | None,\n    offset: int,\n    reason: str,  # e.g., \"empty results\", \"partial results\"\n) -\u003e tuple[bool, bool]:\n    \"\"\"Handle end-of-data condition.\n    \n    Returns:\n        (should_break, should_continue) tuple for control flow\n    \"\"\"\n    if isinstance(coordinator, MultiFolderOffsetCoordinator) and folder_id:\n        logger.info(f\"Worker {worker_id} {reason} for folder {folder_id} at offset {offset}, marking folder complete\")\n        coordinator.mark_folder_complete(folder_id)\n        return (False, True)  # Continue to next folder\n    else:\n        logger.info(f\"Worker {worker_id} {reason} at offset {offset}, marking complete\")\n        coordinator.mark_worker_complete()\n        return (True, False)  # Break from loop\n```\n\n**Usage:**\n```python\n# Empty items\nif not items or len(items) == 0:\n    should_break, should_continue = self._handle_end_of_data(\n        coordinator, worker_id, folder_id, offset, \n        reason=\"hit end-of-data\"\n    )\n    if should_break:\n        break\n    if should_continue:\n        continue\n\n# Fewer items than requested\nif len(items) \u003c limit:\n    should_break, should_continue = self._handle_end_of_data(\n        coordinator, worker_id, folder_id, offset,\n        reason=f\"received {len(items)} \u003c {limit} items\"\n    )\n    if should_break:\n        break\n    if should_continue:\n        continue\n```\n\n## Impact\n\n- **Complexity reduction**: ~30 lines of duplicated branching → single helper method\n- **Maintainability**: Single source of truth for end-of-data handling\n- **Clarity**: Control flow (break/continue) is explicit via return tuple\n- **Consistency**: All end-of-data cases handled identically\n\n## Location\n\nFile: src/lookervault/extraction/parallel_orchestrator.py\nMethod: _parallel_fetch_worker() (lines 586-648)\n\n## Priority\n\nLow (P3) - Code quality improvement. Current code works but is harder to maintain.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:32.255314-07:00","updated_at":"2025-12-31T22:59:45.234198-07:00","closed_at":"2025-12-31T22:59:45.234198-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-hbr","title":"Add comprehensive test coverage for snapshot module (GCS cloud storage)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T20:41:37.920154-07:00","updated_at":"2025-12-14T21:16:47.931986-07:00","closed_at":"2025-12-14T21:16:47.931986-07:00"}
{"id":"lookervault-hi3","title":"Add missing CLI command examples for snapshot operations","description":"README.md has basic snapshot examples but missing: snapshot retention cleanup, snapshot download with filtering, restore from specific snapshot timestamp. Add comprehensive snapshot workflow examples section.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:41:02.689597-07:00","updated_at":"2025-12-14T21:25:08.070683-07:00","closed_at":"2025-12-14T21:25:08.070683-07:00"}
{"id":"lookervault-ht6","title":"Add integration tests for critical workflows (extract → unpack → pack → restore)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T20:44:41.450692-07:00","updated_at":"2025-12-14T20:44:41.450692-07:00"}
{"id":"lookervault-hu3","title":"Implement TODO: dependency validation in restore.py","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:41:46.731724-07:00","updated_at":"2025-12-14T21:42:36.794077-07:00","closed_at":"2025-12-14T21:42:36.794077-07:00"}
{"id":"lookervault-ibh","title":"Document ContentDeserializer read-only field filtering logic","description":"File: src/lookervault/restoration/deserializer.py. Read-only field list (50+ fields) lacks explanation of why each field is excluded. Add comments documenting Looker API Write* model constraints and field categorization.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:42.593464-07:00","updated_at":"2025-12-31T23:53:56.315536-07:00","closed_at":"2025-12-31T23:53:56.315536-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-iop","title":"Add folder_ids parsing and validation to restore.py command modules","description":"CRITICAL: CLI flags --folder-ids and --recursive are defined in main.py but not implemented in cli/commands/restore.py and restore_all.py. Need to: (1) Parse folder_ids from comma-separated string, (2) Validate content types support folder filtering, (3) Resolve hierarchy if recursive, (4) Pass folder_ids list to RestorationConfig. Without this, the feature is non-functional from CLI.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-14T10:59:20.402644-07:00","updated_at":"2025-12-14T11:25:15.034211-07:00","closed_at":"2025-12-14T11:25:15.034211-07:00","dependencies":[{"issue_id":"lookervault-iop","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:20.40331-07:00","created_by":"daemon","metadata":"{}"}]}
{"id":"lookervault-ioz","title":"Add pre-commit hooks configuration for code quality automation","description":"## Problem\n\nNo pre-commit hooks configured. Code quality checks (ruff, ty, pytest) must be run manually, increasing risk of committing code with linting errors, type errors, or failing tests.\n\n## Current State\n\n- ✅ ruff configured in pyproject.toml\n- ✅ ty configured in pyproject.toml  \n- ✅ pytest configured in pyproject.toml\n- ❌ No .pre-commit-config.yaml file\n- ❌ No automated enforcement before commits\n\n## Recommendation\n\nAdd .pre-commit-config.yaml with hooks:\n1. ruff format (auto-format code)\n2. ruff check --fix (lint and auto-fix)\n3. ty check (type checking)\n4. pytest (run test suite)\n\n## Benefits\n\n- Prevents committing code with style/lint errors\n- Catches type errors before push\n- Ensures tests pass before commit\n- Consistent code quality across all commits\n- Follows CLAUDE.md requirements for pre-commit checks\n\n## Implementation\n\n```yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.8.0\n    hooks:\n      - id: ruff-format\n      - id: ruff\n        args: [--fix]\n  \n  - repo: local\n    hooks:\n      - id: ty\n        name: ty type checking\n        entry: uvx ty check\n        language: system\n        pass_filenames: false\n      \n      - id: pytest\n        name: pytest\n        entry: uv run pytest\n        language: system\n        pass_filenames: false\n        stages: [push]\n```\n\n## References\n\n- CLAUDE.md: Pre-Commit Requirements section mandates ALL checks before commit\n- ruff-pre-commit: https://github.com/astral-sh/ruff-pre-commit","status":"closed","priority":1,"issue_type":"chore","created_at":"2025-12-14T20:41:06.564608-07:00","updated_at":"2025-12-14T21:11:36.31344-07:00","closed_at":"2025-12-14T21:11:36.31344-07:00"}
{"id":"lookervault-iw5","title":"Add missing project metadata to pyproject.toml (URLs, keywords, classifiers)","description":"## Problem\n\npyproject.toml is missing optional but recommended project metadata:\n- No project URLs (homepage, repository, documentation, issues)\n- No keywords for package discovery\n- No classifiers for PyPI categorization\n- No readme field\n\n## Current Metadata\n\n```toml\n[project]\nname = \"lookervault\"\nversion = \"0.1.0\"\ndescription = \"LookerVault is a CLI tool that backs up your entire Looker content\"\nauthors = [{ name = \"z3z1ma\", email = \"butler.alex2010@gmail.com\" }]\nrequires-python = \"\u003e=3.13\"\n```\n\n## Recommended Additions\n\n```toml\n[project]\nreadme = \"README.md\"\nkeywords = [\"looker\", \"backup\", \"cli\", \"analytics\", \"bi\", \"content\", \"vault\"]\n\n[project.urls]\nHomepage = \"https://github.com/z3z1ma/lookervault\"\nRepository = \"https://github.com/z3z1ma/lookervault\"\nIssues = \"https://github.com/z3z1ma/lookervault/issues\"\nDocumentation = \"https://github.com/z3z1ma/lookervault/blob/main/README.md\"\n\n# PyPI classifiers (if publishing to PyPI)\nclassifiers = [\n    \"Development Status :: 3 - Alpha\",\n    \"Intended Audience :: Developers\",\n    \"Topic :: Software Development :: Libraries :: Python Modules\",\n    \"Topic :: Database\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.13\",\n    \"Environment :: Console\",\n    \"Typing :: Typed\",\n]\n```\n\n## Benefits\n\n- Better discoverability on PyPI (if published)\n- Clear links to documentation and issue tracker\n- Professional package presentation\n- Helps users understand project maturity and purpose\n\n## Impact\n\nLow priority (P3) - Nice to have, not blocking functionality\n\n## Note\n\nUpdate URLs to match actual repository location if different from example.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-14T20:42:30.064467-07:00","updated_at":"2025-12-31T23:26:04.82086-07:00","closed_at":"2025-12-31T23:26:04.82086-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-j64","title":"Refactor test suite to reduce coupling to implementation details","description":"Several unit tests in the test suite are too tightly coupled to implementation details rather than testing behavior:\n\n## Issues Identified\n\n1. **ThreadPoolExecutor mocking** - Tests patch specific import paths rather than testing parallel execution behavior\n2. **Internal method mocking** - Tests mock internal implementation details like queue operations\n3. **Mock structure brittleness** - Tests break when refactoring internal structure even when behavior is unchanged\n\n## Examples\n\n- tests/unit/restoration/test_parallel_orchestrator.py - Tests ThreadPoolExecutor creation details instead of testing that work executes in parallel\n- Integration tests provide better coverage of actual behavior (worker coordination, thread safety, checkpointing)\n\n## Recommendation\n\n1. Convert implementation-detail unit tests to behavioral integration tests\n2. Keep unit tests focused on public API contracts and observable behavior\n3. Use integration tests with real dependencies (SQLite, threading) for parallel execution verification\n\n## Benefits\n\n- Tests will be more resilient to refactoring\n- Better coverage of actual system behavior\n- Easier to maintain as implementation evolves\n\n## Priority\n\nLow (p3) - Tests are currently passing after fixes, but future refactoring will be easier with behavior-focused tests.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T13:54:45.774393-07:00","updated_at":"2025-12-14T13:54:57.824696-07:00"}
{"id":"lookervault-jv3","title":"Implement unpack/edit/repack workflow for SQLite content","description":"## Overview\n\nEnable users to unpack SQLite content to JSON files on disk, perform large-scale find/replace operations, and repack for restoration.\n\n**Purpose**: Static analysis and bulk editing without BLOB limitations. Users can use grep, sed, Python scripts, and other tools on plain-text JSON files.\n\n## Feasibility Assessment\n\n✅ **HIGHLY FEASIBLE** - LookerVault architecture is well-suited for this workflow:\n\n### Architecture Strengths\n1. **Clean serialization**: MessagePack (msgspec) → trivial to convert to/from JSON\n2. **Rich metadata**: content_type, folder_id, name, owner, timestamps available for disk organization\n3. **Smart restore logic**: Existing update/create logic handles arbitrary content changes\n4. **Sub-resource handling**: Dashboard elements, filters, layouts fully supported\n\n### Critical Limitation: Immutable Queries\n\n⚠️ **Looker queries are immutable** - no `update_query` API method exists\n- Changing query definitions (SQL, filters) requires `create_query()` + ID remapping\n- Dashboard elements reference `query_id` which must be updated to new query slug\n- See: https://cloud.google.com/looker/docs/reference/looker-api/latest/methods/Query/create_query\n\n## Implementation Phases\n\n### Phase 1: Non-Query Field Editing (2-4 days)\n**Deliverables**:\n- `lookervault unpack --output-dir ./content/` - SQLite BLOB → JSON files\n- `lookervault repack --input-dir ./content/` - JSON files → SQLite BLOB\n- Validation: Schema checks, read-only field filtering, dry-run mode\n- Folder structure: `{content_type}/{folder_id}/{name}-{id}.json`\n\n**Editable Fields** (Phase 1):\n- ✅ Dashboard/Look titles, descriptions\n- ✅ Element titles, subtitles\n- ✅ Filter configurations\n- ✅ Layout positioning\n- ✅ Connection names, database references (string replacement)\n\n**Not Editable** (Phase 1):\n- ❌ Query definitions (SQL, filters, fields) - requires Phase 2\n\n### Phase 2: Query Recreation Logic (4-6 days, future)\n**Deliverables**:\n- Query definition change detection (hashing)\n- Automatic `create_query()` calls for modified queries\n- Old ID → new ID remapping\n- Query deduplication (reuse existing queries with same definition)\n\n## Workflow Example\n\n```bash\n# Unpack to JSON\nlookervault unpack --output-dir ./looker_content/\n\n# Bulk find/replace\ngrep -r \"old_db_name\" ./looker_content/ -l | xargs sed -i 's/old_db_name/new_db_name/g'\n\n# Validate changes\nlookervault repack --validate --dry-run --input-dir ./looker_content/\n\n# Repack to SQLite\nlookervault repack --input-dir ./looker_content/\n\n# Restore to Looker\nlookervault restore bulk dashboards looks\n```\n\n## Risks\n\n- **Low**: JSON conversion, non-query edits, validation logic\n- **Medium**: Query recreation, large-scale find/replace user errors\n- **High**: Cross-instance ID remapping (not planned), query syntax validation\n\n## Recommendation\n\n✅ Implement **Phase 1 immediately** - delivers 80% of value with minimal risk\n⏸ Defer **Phase 2** based on user demand for query modification support","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-14T15:30:31.652286-07:00","updated_at":"2025-12-14T21:04:54.894622-07:00","closed_at":"2025-12-14T21:04:54.894622-07:00"}
{"id":"lookervault-jv3.1","title":"Phase 1: Implement unpack/repack for non-query fields","description":"Implement basic unpack/repack workflow supporting non-query field edits.\n\n## Tasks\n\n1. **Unpack Command** (4-6 hours):\n   - Read content_items from SQLite\n   - Deserialize msgpack → dict using MsgpackSerializer\n   - Organize by folder: {content_type}/{folder_id}/{name}-{id}.json\n   - Write pretty-printed JSON with __metadata__ header\n   - Preserve original BLOBs for rollback safety\n\n2. **Repack Command** (4-6 hours):\n   - Read JSON files from disk\n   - Validate schema using ContentDeserializer.validate_schema()\n   - Filter read-only fields (50+ fields from deserializer.py)\n   - Serialize dict → msgpack\n   - Update content_items.content_data BLOB\n   - Update updated_at timestamp\n\n3. **Validation Logic** (2-3 hours):\n   - JSON schema validation\n   - Read-only field detection and warnings\n   - Dry-run mode (--dry-run flag)\n\n4. **CLI Integration** (2-3 hours):\n   - Add lookervault unpack command\n   - Add lookervault repack command\n   - Flags: --output-dir, --input-dir, --validate, --dry-run\n\n5. **Testing** (4-6 hours):\n   - Unit tests for serialization/deserialization\n   - Integration tests for unpack → edit → repack → restore\n   - Validation tests for read-only field filtering\n   - Test with 100+ dashboards for performance\n\n## Editable Fields\n\n✅ Titles, descriptions, element titles, filter configs, layouts, connection names, DB refs\n❌ Query definitions (SQL, filters) - deferred to Phase 2\n\n## Acceptance Criteria\n\n- Users can unpack content to organized JSON folder structure\n- Users can perform find/replace with sed/grep/Python\n- Users can repack edited JSON back to SQLite\n- Validation detects read-only field modifications\n- Dry-run mode prevents accidental commits\n- Existing restore commands work with repacked content\n\n## Effort: 2-4 days (1 developer)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-14T15:31:13.398277-07:00","updated_at":"2025-12-14T21:04:41.954527-07:00","closed_at":"2025-12-14T21:04:41.954527-07:00","dependencies":[{"issue_id":"lookervault-jv3.1","depends_on_id":"lookervault-jv3","type":"parent-child","created_at":"2025-12-14T15:31:13.398858-07:00","created_by":"daemon","metadata":"{}"}]}
{"id":"lookervault-jv3.2","title":"Phase 2: Implement query recreation and ID remapping","description":"Add support for editing query definitions with automatic query recreation and ID remapping.\n\n## Background\n\nLooker queries are **immutable** - no update_query API method exists. To \"update\" a query:\n1. Create new query with create_query() (modified definition)\n2. Get new query slug/ID from response\n3. Update dashboard element's query_id field with new ID\n\nSource: https://cloud.google.com/looker/docs/reference/looker-api/latest/methods/Query/create_query\n\n## Tasks\n\n1. **Query Diffing** (6-8 hours):\n   - Implement query definition hashing (SHA256 of SQL + filters + fields)\n   - Compare original vs edited query definitions\n   - Identify modified queries in dashboard elements\n\n2. **Query Creation** (6-8 hours):\n   - Call sdk.create_query() for modified query definitions\n   - Handle API errors and rate limiting with retry logic\n   - Track old_id → new_id mappings in restoration session\n   - Query deduplication: reuse existing queries with same definition\n\n3. **ID Remapping** (4-6 hours):\n   - Update query_id in dashboard elements referencing modified queries\n   - Update JSON files with new query IDs before restoration\n   - Persist ID mappings for audit trail (restoration_sessions table)\n\n4. **Integration** (4-6 hours):\n   - Integrate with existing restoration logic (LookerContentRestorer)\n   - Handle query recreation before dashboard element restoration\n   - Update sub-resource restorer to use remapped IDs\n\n5. **Testing** (6-8 hours):\n   - Unit tests for query diffing and hashing\n   - Integration tests for query recreation workflow\n   - Edge cases: query deduplication, API errors, rollback\n   - Performance test with 1000+ query modifications\n\n## Acceptance Criteria\n\n- Users can edit query SQL/filters/fields in JSON files\n- System automatically creates new queries via create_query()\n- Dashboard elements updated with new query_id references\n- Query deduplication prevents duplicate query creation\n- ID mappings persisted for audit and rollback\n- Restore command handles query recreation transparently\n\n## Editable Fields (Phase 2)\n\n✅ Query SQL, filters, fields, model, view, limit, sorts, pivots, etc.\n\n## Effort: 4-6 days (1 developer)\n\n## Dependencies\n\n- Blocked by: lookervault-jv3.1 (Phase 1 must be completed first)\n- Requires: Phase 1 unpack/repack infrastructure","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-14T15:31:32.62554-07:00","updated_at":"2025-12-14T21:04:42.924491-07:00","closed_at":"2025-12-14T21:04:42.924491-07:00","dependencies":[{"issue_id":"lookervault-jv3.2","depends_on_id":"lookervault-jv3","type":"parent-child","created_at":"2025-12-14T15:31:32.626037-07:00","created_by":"daemon","metadata":"{}"}]}
{"id":"lookervault-jv3.3","title":"Phase 2: Implement query recreation and ID remapping","description":"Add support for editing query definitions with automatic query recreation and ID remapping.\n\n## Background\n\nLooker queries are **immutable** - no update_query API method exists. To \"update\" a query:\n1. Create new query with create_query() (modified definition)\n2. Get new query slug/ID from response\n3. Update dashboard element's query_id field with new ID\n\nSource: https://cloud.google.com/looker/docs/reference/looker-api/latest/methods/Query/create_query\n\n## Tasks\n\n1. **Query Diffing** (6-8 hours):\n   - Implement query definition hashing (SHA256 of SQL + filters + fields)\n   - Compare original vs edited query definitions\n   - Identify modified queries in dashboard elements\n\n2. **Query Creation** (6-8 hours):\n   - Call sdk.create_query() for modified query definitions\n   - Handle API errors and rate limiting with retry logic\n   - Track old_id → new_id mappings in restoration session\n   - Query deduplication: reuse existing queries with same definition\n\n3. **ID Remapping** (4-6 hours):\n   - Update query_id in dashboard elements referencing modified queries\n   - Update JSON files with new query IDs before restoration\n   - Persist ID mappings for audit trail (restoration_sessions table)\n\n4. **Integration** (4-6 hours):\n   - Integrate with existing restoration logic (LookerContentRestorer)\n   - Handle query recreation before dashboard element restoration\n   - Update sub-resource restorer to use remapped IDs\n\n5. **Testing** (6-8 hours):\n   - Unit tests for query diffing and hashing\n   - Integration tests for query recreation workflow\n   - Edge cases: query deduplication, API errors, rollback\n   - Performance test with 1000+ query modifications\n\n## Acceptance Criteria\n\n- Users can edit query SQL/filters/fields in JSON files\n- System automatically creates new queries via create_query()\n- Dashboard elements updated with new query_id references\n- Query deduplication prevents duplicate query creation\n- ID mappings persisted for audit and rollback\n- Restore command handles query recreation transparently\n\n## Editable Fields (Phase 2)\n\n✅ Query SQL, filters, fields, model, view, limit, sorts, pivots, etc.\n\n## Effort: 4-6 days (1 developer)","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-14T15:31:56.438414-07:00","updated_at":"2025-12-14T21:04:43.866567-07:00","closed_at":"2025-12-14T21:04:43.866567-07:00","dependencies":[{"issue_id":"lookervault-jv3.3","depends_on_id":"lookervault-jv3","type":"parent-child","created_at":"2025-12-14T15:31:56.439059-07:00","created_by":"daemon","metadata":"{}"}]}
{"id":"lookervault-jv3.4","title":"Phase 2: Implement query recreation and ID remapping","description":"Add support for editing query definitions with automatic query recreation and ID remapping.\n\n## Background\n\nLooker queries are **immutable** - no update_query API method exists. To \"update\" a query:\n1. Create new query with create_query() (modified definition)\n2. Get new query slug/ID from response\n3. Update dashboard element's query_id field with new ID\n\nSource: https://cloud.google.com/looker/docs/reference/looker-api/latest/methods/Query/create_query\n\n## Tasks\n\n1. **Query Diffing** (6-8 hours):\n   - Implement query definition hashing (SHA256 of SQL + filters + fields)\n   - Compare original vs edited query definitions\n   - Identify modified queries in dashboard elements\n\n2. **Query Creation** (6-8 hours):\n   - Call sdk.create_query() for modified query definitions\n   - Handle API errors and rate limiting with retry logic\n   - Track old_id → new_id mappings in restoration session\n   - Query deduplication: reuse existing queries with same definition\n\n3. **ID Remapping** (4-6 hours):\n   - Update query_id in dashboard elements referencing modified queries\n   - Update JSON files with new query IDs before restoration\n   - Persist ID mappings for audit trail (restoration_sessions table)\n\n4. **Integration** (4-6 hours):\n   - Integrate with existing restoration logic (LookerContentRestorer)\n   - Handle query recreation before dashboard element restoration\n   - Update sub-resource restorer to use remapped IDs\n\n5. **Testing** (6-8 hours):\n   - Unit tests for query diffing and hashing\n   - Integration tests for query recreation workflow\n   - Edge cases: query deduplication, API errors, rollback\n   - Performance test with 1000+ query modifications\n\n## Acceptance Criteria\n\n- Users can edit query SQL/filters/fields in JSON files\n- System automatically creates new queries via create_query()\n- Dashboard elements updated with new query_id references\n- Query deduplication prevents duplicate query creation\n- ID mappings persisted for audit and rollback\n- Restore command handles query recreation transparently\n\n## Editable Fields (Phase 2)\n\n✅ Query SQL, filters, fields, model, view, limit, sorts, pivots, etc.\n\n## Effort: 4-6 days (1 developer)","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-14T15:32:06.327413-07:00","updated_at":"2025-12-14T21:04:44.763279-07:00","closed_at":"2025-12-14T21:04:44.763279-07:00","dependencies":[{"issue_id":"lookervault-jv3.4","depends_on_id":"lookervault-jv3","type":"parent-child","created_at":"2025-12-14T15:32:06.327942-07:00","created_by":"daemon","metadata":"{}"},{"issue_id":"lookervault-jv3.4","depends_on_id":"lookervault-jv3.1","type":"blocks","created_at":"2025-12-14T15:32:06.328527-07:00","created_by":"daemon","metadata":"{}"}]}
{"id":"lookervault-kku","title":"Remove unused --fix-dependencies flag from restore dlq retry command (not implemented)","description":"## Location\n\nsrc/lookervault/cli/main.py:775-777\nsrc/lookervault/cli/commands/restore.py:1477, 1489\n\n## Evidence\n\nFlag is defined in CLI:\n```python\nfix_dependencies: Annotated[\n    bool,\n    typer.Option('--fix-dependencies', help='Attempt to fix dependency issues'),\n] = False\n```\n\nBut in restore.py line 1489, the docstring says:\n```\nfix_dependencies: Attempt to fix dependency issues (not implemented)\n```\n\nThe parameter is accepted but never used in the retry logic.\n\n## Impact\n\n- Misleads users into thinking dependency fixing is available\n- No actual implementation\n- Just a placeholder for future feature\n\n## Safe to Remove\n\nThis is documented as 'not implemented' in the code itself, so clearly was never finished.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:53:27.467866-07:00","updated_at":"2025-12-31T23:26:04.812738-07:00","closed_at":"2025-12-31T23:26:04.812738-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-llz","title":"Add module-level docstrings for CLI command modules","description":"Files: src/lookervault/cli/commands/*.py. Several command modules (extract.py, restore.py, snapshot.py) have minimal or missing module-level docstrings. Add comprehensive module docstrings explaining command purpose and usage.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:34.516504-07:00","updated_at":"2026-01-01T00:06:23.090621-07:00","closed_at":"2026-01-01T00:06:23.090621-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-m23","title":"Remove unused function parameter 'force' in restore_single()","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:54:08.878734-07:00","updated_at":"2025-12-31T22:31:32.870748-07:00","closed_at":"2025-12-31T22:31:32.870748-07:00","close_reason":"Completed - removed unused parameters"}
{"id":"lookervault-mhn","title":"Simplify convoluted logic: Replace monkey-patching with explicit parameter passing in resume()","description":"## Problem\n\nThe resume() method in parallel_orchestrator.py uses monkey-patching to temporarily override repository.get_content_ids() (lines 615-640). This is convoluted and hard to understand:\n\n**Current implementation:**\n```python\n# Save original method\noriginal_get_content_ids = self.repository.get_content_ids\n\n# Create wrapper function\ndef filtered_get_content_ids(content_type_value: int) -\u003e list[str]:\n    if content_type_value == content_type.value:\n        return remaining_ids\n    return original_get_content_ids(content_type_value)\n\n# Monkey-patch the repository method temporarily\nself.repository.get_content_ids = filtered_get_content_ids\n\ntry:\n    summary = self.restore(content_type, session_id)\nfinally:\n    # Restore original method\n    self.repository.get_content_ids = original_get_content_ids\n```\n\n**Code smells:**\n- Monkey-patching is a code smell - hard to understand control flow\n- Side effects on shared object (repository)\n- Risk of forgetting to restore original method if exception handling breaks\n- Makes testing harder - mutable state during execution\n- Not thread-safe (if resume() called concurrently)\n\n## Simpler Alternative\n\n**Option 1: Add explicit content_ids parameter to restore():**\n```python\ndef restore(\n    self, \n    content_type: ContentType, \n    session_id: str,\n    content_ids: list[str] | None = None  # NEW: explicit parameter\n) -\u003e RestorationSummary:\n    # Use provided content_ids if available, else query repository\n    if content_ids is None:\n        content_ids = self.repository.get_content_ids(content_type.value)\n    \n    # ... rest of restore logic\n```\n\nThen resume() becomes:\n```python\ndef resume(...):\n    # ... get checkpoint, extract completed_ids\n    remaining_ids = [cid for cid in all_content_ids if cid not in completed_ids]\n    \n    # Simple, explicit parameter passing - no monkey-patching!\n    return self.restore(content_type, session_id, content_ids=remaining_ids)\n```\n\n**Option 2: Extract private method with explicit filtering:**\n```python\ndef _restore_with_filter(\n    self,\n    content_type: ContentType,\n    session_id: str,\n    content_ids: list[str]\n) -\u003e RestorationSummary:\n    # Restore logic with explicit content_ids list (no repository query)\n    ...\n```\n\n## Impact\n\n- **Clarity**: Explicit parameter passing is immediately understandable\n- **Safety**: No risk of forgetting to restore original method\n- **Thread-safety**: No shared mutable state during execution\n- **Testability**: Easier to test with explicit parameters\n- **Maintainability**: Standard Python patterns instead of metaprogramming tricks\n\n## Location\n\nFile: /src/lookervault/restoration/parallel_orchestrator.py\nMethod: resume() (lines 615-640)\n\n## Priority\n\nMedium (P2) - This is genuinely hard to understand code. Monkey-patching should be avoided when simple alternatives exist.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:53:38.687771-07:00","updated_at":"2025-12-31T21:38:47.879299-07:00","closed_at":"2025-12-31T21:38:47.879299-07:00","close_reason":"Completed via parallel sub-agents"}
{"id":"lookervault-mwr","title":"Create quickstart guide for YAML modification workflow","description":"docs/yaml-export-import.md exists but no quickstart guide. Need to create docs/yaml-quickstart.md with step-by-step tutorial: extract dashboards, unpack to YAML, modify with sed, pack back, verify, restore. Include common pitfall warnings.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:40:57.986675-07:00","updated_at":"2025-12-14T21:24:38.96007-07:00","closed_at":"2025-12-14T21:24:38.96007-07:00"}
{"id":"lookervault-nfw","title":"Fix current ruff linting errors (11 errors found)","description":"## Problem\n\nRunning `uvx ruff check` shows 11 linting errors:\n- 3x F401: unused-import\n- 3x F841: unused-variable\n- 2x PTH123: builtin-open (should use pathlib)\n- 1x I001: unsorted-imports\n- 1x S110: try-except-pass\n- 1x UP015: redundant-open-modes\n\n5 are auto-fixable with `--fix` flag.\n\n## Impact\n\n- Code quality issues accumulate\n- Violates project code conventions\n- May indicate dead code or incomplete refactoring\n\n## Recommendation\n\n1. Run `uvx ruff check --fix` to auto-fix 5 errors\n2. Manually fix remaining 6 errors:\n   - Remove unused variables (F841)\n   - Replace builtin open() with pathlib (PTH123)\n   - Add explicit handling to try-except-pass (S110)\n\n## Commands\n\n```bash\n# Auto-fix what's possible\nuvx ruff check --fix\n\n# View remaining errors with context\nuvx ruff check --show-files\n\n# Fix manually, then verify\nuvx ruff check\n```\n\n## Priority\n\nHigh (P1) - Should be fixed before adding pre-commit hooks to prevent blocking commits","status":"closed","priority":1,"issue_type":"chore","created_at":"2025-12-14T20:41:31.779938-07:00","updated_at":"2025-12-14T21:10:18.457976-07:00","closed_at":"2025-12-14T21:10:18.457976-07:00"}
{"id":"lookervault-nsf","title":"Add project license to pyproject.toml and LICENSE file","description":"## Problem\n\nNo license specified in pyproject.toml. Missing LICENSE file. This creates legal ambiguity:\n- Users don't know if they can use/modify/distribute the code\n- PyPI package will show \"License: UNKNOWN\"\n- Not following Python packaging best practices\n\n## Current State\n\n- ❌ No `license` field in [project] metadata\n- ❌ No LICENSE file in repository root\n- ✅ Has author information\n\n## Recommendation\n\n1. Choose a license (common choices):\n   - **MIT**: Permissive, allows commercial use (most popular for tools)\n   - **Apache 2.0**: Permissive with patent grant\n   - **GPL-3.0**: Copyleft, requires derivative works to be open source\n   - **Proprietary**: If this is internal/closed source only\n\n2. Add to pyproject.toml:\n```toml\n[project]\nlicense = {text = \"MIT\"}  # or {file = \"LICENSE\"}\n```\n\n3. Create LICENSE file with full license text\n\n## Impact\n\nMedium priority - Important for distribution/sharing but not blocking functionality\n\n## Questions for Maintainer\n\n- Is this intended to be open source or proprietary?\n- If open source, which license do you prefer?","status":"in_progress","priority":2,"issue_type":"chore","created_at":"2025-12-14T20:41:42.673465-07:00","updated_at":"2025-12-14T21:22:54.337376-07:00"}
{"id":"lookervault-nzc","title":"Remove or implement unused CLI parameters (verbose, debug, dry_run)","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:11.854153-07:00","updated_at":"2025-12-31T23:14:19.151888-07:00","closed_at":"2025-12-31T23:14:19.151888-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-or9","title":"Add comprehensive test coverage for export/import (YAML pack/unpack) module","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T20:41:15.969691-07:00","updated_at":"2025-12-14T21:15:53.888332-07:00","closed_at":"2025-12-14T21:15:53.888332-07:00"}
{"id":"lookervault-p6i","title":"Remove unused OutputConfig class - fields never accessed","description":"## Evidence of Non-Use\n\nOutputConfig class defined in src/lookervault/config/models.py (lines 22-27) with fields:\n- default_format: Literal['table', 'json'] = 'table'\n- color_enabled: bool = True\n\nGrep search shows NO references to:\n- .output. or config.output in src/lookervault\n- default_format outside of models.py\n- color_enabled outside of models.py\n\n## Impact\n\nDead code that adds maintenance burden:\n- Misleads developers into thinking output format is configurable via config file\n- Takes up space in Configuration model\n- Could cause confusion about where CLI output format is controlled (it's only via --output flag)\n\n## Safe to Remove\n\n- Not referenced anywhere in actual code\n- Only exists in Configuration model and example config files\n- CLI commands use --output flag directly, not config.output.default_format","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:53:23.505001-07:00","updated_at":"2025-12-31T23:39:19.308647-07:00","closed_at":"2025-12-31T23:39:19.308647-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-qvv","title":"Add test coverage for folder hierarchy resolver and recursive expansion","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T20:42:22.335118-07:00","updated_at":"2025-12-14T21:13:53.094294-07:00","closed_at":"2025-12-14T21:13:53.094294-07:00"}
{"id":"lookervault-rfc","title":"Remove unused dependency: tomli-w","description":"## Problem\n\ntomli-w is listed in project.dependencies but is NEVER imported anywhere in the codebase:\n- Specified: `tomli-w\u003e=1.0.0` in pyproject.toml line 20\n- Actual usage: Zero imports (verified with grep -r \"tomli_w\")\n- Purpose: TOML writing (Python 3.11+ stdlib has tomllib for READING, but no writer)\n- Reality: Project ONLY reads TOML configs, never writes them\n\n## Evidence\n\n```bash\n$ grep -r \"import tomli_w|from tomli_w\" src/\n# (empty - no imports found)\n\n$ grep -r \"tomllib\" src/\nsrc/lookervault/config/loader.py:import tomllib  # stdlib for reading\n```\n\n## Current TOML Usage\n\nconfig/loader.py uses stdlib tomllib for READING config files:\n```python\nimport tomllib\nwith open(config_file, \"rb\") as f:\n    config_data = tomllib.load(f)\n```\n\nProject never writes TOML files - only reads user-provided looker.toml configs.\n\n## Impact\n\n- Unnecessary C extension dependency (~50KB + build overhead)\n- Adds confusing build-time dependency\n- No value provided (100% dead code)\n\n## Solution\n\n```bash\nuv remove tomli-w\n```\n\n## Notes\n\n- If future TOML writing needed, can add back then\n- Current use case (config reading) fully covered by stdlib tomllib","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-14T20:54:14.268639-07:00","updated_at":"2025-12-31T22:47:13.249884-07:00","closed_at":"2025-12-31T22:47:13.249884-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-sco","title":"Remove unused imports in test files (3 occurrences)","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:05.43012-07:00","updated_at":"2025-12-31T23:14:19.154307-07:00","closed_at":"2025-12-31T23:14:19.154307-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-tdo","title":"Extract magic numbers to named constants throughout codebase","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:39.552748-07:00","updated_at":"2025-12-14T20:41:39.552748-07:00"}
{"id":"lookervault-tnp","title":"Add missing docstrings for ContentRepository protocol methods","description":"File: src/lookervault/storage/repository.py. ContentRepository protocol has methods like save_content, get_content, list_content that lack complete docstrings. Need to add Returns, Raises, and Examples sections to all protocol methods for better developer documentation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:40:46.309486-07:00","updated_at":"2025-12-14T21:11:09.04321-07:00","closed_at":"2025-12-14T21:11:09.04321-07:00"}
{"id":"lookervault-tp9","title":"Remove unused method parameter 'strategy' in ContentPacker._discover_yaml_files()","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:41.830334-07:00","updated_at":"2025-12-31T22:47:13.247961-07:00","closed_at":"2025-12-31T22:47:13.247961-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-u7w","title":"Document rate limiter adaptive recovery algorithm","description":"File: src/lookervault/extraction/rate_limiter.py. AdaptiveRateLimiter has sliding window + backoff algorithm but lacks inline comments. Add comments explaining token bucket refill, 429 detection, gradual recovery phases.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:38.997179-07:00","updated_at":"2026-01-01T00:06:23.092306-07:00","closed_at":"2026-01-01T00:06:23.092306-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-unu","title":"Add unit tests for rate limiter and adaptive backoff logic","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T20:41:59.929604-07:00","updated_at":"2025-12-14T21:13:42.472394-07:00","closed_at":"2025-12-14T21:13:42.472394-07:00"}
{"id":"lookervault-uu2","title":"Consider removing unused --owner filter from list command (not queryable, requires post-filter)","description":"## Location\n\nsrc/lookervault/cli/commands/list.py:87-92\n\n## Evidence\n\nFlag is defined and partially implemented with post-filtering:\n```python\nif owner:\n    items = [\n        item for item in items\n        if item.owner_email and owner.lower() in item.owner_email.lower()\n    ]\n```\n\n## Why Consider Removing\n\n**Performance Issue**:\n- Queries ALL items from database first\n- Then filters in Python (memory inefficient)\n- For large datasets, this defeats pagination (--limit, --offset)\n\n**Better Alternative Exists**:\n- owner_email is stored in content_items table\n- Could add WHERE clause to SQL query for efficient filtering\n- But if not used, better to remove than optimize\n\n## Decision Needed\n\n1. Remove the flag (if nobody uses it)\n2. Implement properly with SQL WHERE clause (if needed)\n3. Leave as-is (works but inefficient)\n\nMark as P3 cleanup since it works but is inefficient. Check usage before deciding.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:49.758372-07:00","updated_at":"2025-12-31T23:39:19.313166-07:00","closed_at":"2025-12-31T23:39:19.313166-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-vpp","title":"Address ty type checker warnings and errors","description":"## Problem\n\nRunning `uvx ty check` shows several type errors:\n1. **msgspec.msgpack unresolved** (7 occurrences): ty doesn't recognize msgspec.msgpack attribute (false positive - it exists at runtime)\n2. **possibly-unbound-attribute** (2 warnings): coordinator.mark_worker_complete() on union type\n3. **invalid-assignment** (1 error): dict[ContentType, int] type mismatch in dependency_graph.py\n\n## Analysis\n\n### 1. msgspec.msgpack errors (FALSE POSITIVE)\nVerified msgspec.msgpack exists: `python -c \"import msgspec; print('msgpack' in dir(msgspec))\"`\nThis is a ty type checker limitation with msgspec stubs.\n\n### 2. Union type method calls\n```python\ncoordinator: OffsetCoordinator | MultiFolderOffsetCoordinator\ncoordinator.mark_worker_complete()  # ty can't verify both types have this method\n```\n\n### 3. dict.fromkeys type inference\n```python\nstate: dict[ContentType, int] = dict.fromkeys(self.DEPENDENCIES, white)\n# dict.fromkeys returns dict[Unknown, Literal[0]], not dict[ContentType, int]\n```\n\n## Recommendations\n\n1. **msgspec issue**: Add `# type: ignore[unresolved-attribute]` comments or suppress via ty config\n2. **Union methods**: Add type guard or cast to help ty narrow the type\n3. **dict.fromkeys**: Use dict comprehension instead: `{k: white for k in self.DEPENDENCIES}`\n\n## Impact\n\nMedium priority - Doesn't affect runtime but blocks clean type checking\n\n## Configuration Option\n\nAdd to pyproject.toml:\n```toml\n[tool.ty.rules]\nunresolved-attribute = \"warn\"  # Downgrade to warning instead of error\n```","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-14T20:41:57.313069-07:00","updated_at":"2025-12-31T21:38:47.883522-07:00","closed_at":"2025-12-31T21:38:47.883522-07:00","close_reason":"Completed via parallel sub-agents"}
{"id":"lookervault-vqw","title":"Add missing type hints on storage repository helper methods","description":"File: src/lookervault/storage/repository.py lines 500-800. Several private helper methods (_retry_on_sqlite_busy, _execute_with_retry, etc.) missing return type hints. Add proper type annotations for all internal methods.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:40:48.561389-07:00","updated_at":"2025-12-14T20:40:48.561389-07:00"}
{"id":"lookervault-vtq","title":"Refactor parallel_orchestrator.py - long methods and high complexity","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T20:41:40.976557-07:00","updated_at":"2025-12-14T20:41:40.976557-07:00"}
{"id":"lookervault-wkm","title":"Remove redundant dependency: google-crc32c (transitive from google-cloud-storage)","description":"## Problem\n\ngoogle-crc32c is listed as direct dependency but is ALREADY a transitive dependency of google-cloud-storage:\n- Specified: `google-crc32c\u003e=1.7.1` in pyproject.toml line 11\n- Reality: google-cloud-storage ALREADY depends on it\n- Usage: Only imported in snapshot/downloader.py for checksum verification\n- Redundancy: Listed twice (direct + transitive)\n\n## Evidence\n\n```bash\n$ uv tree | grep -B 2 -A 2 google-crc32c\n├── google-cloud-storage v3.7.0\n│   ├── google-api-core v2.28.1 (*)\n│   ├── google-crc32c v1.7.1         # ← Transitive dependency\n│   ├── google-resumable-media v2.8.0\n│   │   └── google-crc32c v1.7.1     # ← Also transitive here\n├── google-crc32c v1.7.1              # ← Direct (REDUNDANT)\n```\n\n```python\n# Only usage in codebase\nsrc/lookervault/snapshot/downloader.py:\nimport google_crc32c  # For GCS download verification\n```\n\n## Impact\n\n- Redundant dependency specification (confusing)\n- No practical benefit (would be installed anyway)\n- Maintenance burden (duplicate version management)\n\n## Solution\n\nRemove from pyproject.toml:\n```bash\nuv remove google-crc32c\n```\n\ngoogle-cloud-storage will continue to provide it as transitive dependency.\n\n## Safety\n\n✅ Safe to remove - google-cloud-storage depends on same version\n✅ Code continues working - imports resolve to transitive dependency\n✅ Version management simplified - single source of truth\n\n## Notes\n\n- If future use case needs google-crc32c WITHOUT google-cloud-storage, add back then\n- Current use case (GCS checksum verification) fully covered by transitive dep","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-14T20:54:42.250234-07:00","updated_at":"2025-12-31T22:31:26.422952-07:00","closed_at":"2025-12-31T22:31:26.422952-07:00","close_reason":"NOT CHANGED - google-crc32c is directly imported and required"}
{"id":"lookervault-wll","title":"Reduce duplication in error handling - bare except Exception with pass/log pattern","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:41:42.93263-07:00","updated_at":"2026-01-01T00:06:23.088423-07:00","closed_at":"2026-01-01T00:06:23.088423-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-wm0","title":"Remove unused 'pass' statements in exception class definitions","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T20:54:16.947183-07:00","updated_at":"2025-12-31T22:59:45.238012-07:00","closed_at":"2025-12-31T22:59:45.238012-07:00","close_reason":"Completed via parallel execution"}
{"id":"lookervault-x6i","title":"Add error handling tests for CLI commands (pack, unpack, snapshot, verify, etc.)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:42:46.856109-07:00","updated_at":"2025-12-14T21:46:57.728304-07:00","closed_at":"2025-12-14T21:46:57.728304-07:00"}
{"id":"lookervault-xh7","title":"Document performance characteristics for folder filtering","description":"CLAUDE.md documents multi-folder SDK optimization but README lacks performance examples. Add performance section explaining 10-100x speedup for folder filtering, include benchmarks for 1/3/10 folders.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T20:40:59.118928-07:00","updated_at":"2025-12-14T20:40:59.118928-07:00"}
{"id":"lookervault-xlw","title":"Remove or implement unused parameters in restore_dlq functions","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T20:54:10.360193-07:00","updated_at":"2025-12-31T22:31:32.8729-07:00","closed_at":"2025-12-31T22:31:32.8729-07:00","close_reason":"Completed - removed unused parameters"}
{"id":"lookervault-yos","title":"Make all SQLite write operations idempotent (upsert)","description":"## Problem\n\nCurrently when running multiple extractions, the system appends content instead of performing upsert operations. This breaks the most common workflow: pull snapshot → run partial extract to update → upload updated snapshot.\n\n## Current State Analysis\n\n**Already Upsert (✅)**:\n- save_content(): Uses INSERT ... ON CONFLICT(id) DO UPDATE SET\n- save_id_mapping(): Uses INSERT ... ON CONFLICT(...) DO UPDATE SET\n\n**Plain INSERT (❌ - Needs Fix)**:\n- save_checkpoint(): Lines 601-655\n- create_session(): Lines 758-792\n- save_dead_letter_item(): Lines 1158-1214\n- save_restoration_checkpoint(): Lines 1612-1666\n- create_restoration_session(): Lines 1769-1822\n\n## Impact\n\nWithout upsert operations:\n- Running extract twice creates duplicate checkpoint entries or fails on PK violation\n- Resuming with same session_id fails instead of updating existing session\n- DLQ items can be duplicated if retry logic re-saves same failure\n- Cannot safely re-run partial extractions to update snapshots\n\n## Requirements\n\nALL write operations must be idempotent:\n1. Running operation twice with same data = same final state\n2. No errors on re-run (no PK violations)\n3. Updates existing records instead of creating duplicates\n4. Safe for the workflow: pull → partial extract → upload\n\n## Acceptance Criteria\n\n- [ ] save_checkpoint() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] create_session() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] save_dead_letter_item() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] save_restoration_checkpoint() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] create_restoration_session() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] All operations tested with duplicate calls (verify idempotency)\n- [ ] No database schema changes required (current PKs/constraints sufficient)","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-14T12:15:10.356229-07:00","updated_at":"2025-12-14T13:00:28.094881-07:00","closed_at":"2025-12-14T13:00:28.094881-07:00"}

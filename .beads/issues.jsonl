{"id":"lookervault-0me","title":"Cache resolved folder hierarchy in extraction session metadata for resume capability","description":"Cache the resolved folder hierarchy (folder_ids after recursive expansion) in extraction session metadata. This allows resume operations to skip folder hierarchy re-resolution. Currently hierarchy is re-resolved on every extraction. Small memory overhead (~10KB per 1000 folders) for significant resume speedup.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T10:59:18.1774-07:00","updated_at":"2025-12-14T11:24:42.551722-07:00","closed_at":"2025-12-14T11:24:42.551722-07:00","dependencies":[{"issue_id":"lookervault-0me","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:18.178155-07:00","created_by":"daemon"}]}
{"id":"lookervault-73h","title":"Add folder-level filtering for extract and restore operations","description":"Add ability to target specific Looker folders for extraction and restoration operations.\n\nCurrent behavior:\n- Extract/restore operates on entire content types (all dashboards, all looks, etc.)\n- No way to selectively backup/restore content within specific folders\n\nDesired behavior:\n- Extract: --folder-id flag to extract only content within a specific folder (and optionally subfolders with --recursive)\n- Restore: --folder-id flag to restore only content that belonged to specific folders\n- Useful for: selective backups, team-specific workflows, testing on smaller subsets, partial restorations\n\nImplementation considerations:\n- Looker API supports folder filtering on content endpoints\n- May need to handle folder hierarchy (parent/child relationships)\n- Should work with existing parallel extraction/restoration architecture\n- Consider whether to extract folder metadata separately or inline with content","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-13T23:08:37.681778-07:00","updated_at":"2025-12-14T10:52:21.136309-07:00","closed_at":"2025-12-14T10:52:21.136309-07:00"}
{"id":"lookervault-7p7","title":"Add indexed folder_id column to content_items table for faster SQL filtering","description":"Add a dedicated folder_id column to the content_items table with a partial index for faster SQL-based folder filtering. Currently folder_id is stored in the serialized content_data BLOB requiring Python-side deserialization for filtering. Benefits: 10-100x faster folder-filtered queries, enables SQL WHERE clauses, reduces memory usage. Requires schema migration.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T10:59:16.111871-07:00","updated_at":"2025-12-14T11:39:52.135358-07:00","closed_at":"2025-12-14T11:39:52.135358-07:00","dependencies":[{"issue_id":"lookervault-7p7","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:16.112838-07:00","created_by":"daemon"}]}
{"id":"lookervault-83w","title":"Implement dashboard sub-resource restoration (elements, filters, layouts)","description":"","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-13T21:59:46.610527-07:00","updated_at":"2025-12-13T22:08:35.483289-07:00","closed_at":"2025-12-13T22:08:35.483289-07:00"}
{"id":"lookervault-dil","title":"Replace multi-folder in-memory filtering with parallel SDK calls (critical perf optimization)","description":"CRITICAL PERFORMANCE: Replaced multi-folder in-memory filtering with parallel SDK API calls for 10-100x performance improvement.\n\n**COMPLETED** (Phase 1 \u0026 2):\n- ✅ MultiFolderOffsetCoordinator class with round-robin folder selection\n- ✅ Per-folder offset tracking with thread-safe coordination\n- ✅ Modified _parallel_fetch_worker() to support multi-folder coordinator\n- ✅ Updated _extract_parallel() to create MultiFolderOffsetCoordinator when appropriate\n- ✅ Removed in-memory filtering code (SDK handles filtering)\n- ✅ Updated CLAUDE.md with optimization details\n\n**PENDING** (Phase 3 - Testing):\n- ⏳ Unit tests for MultiFolderOffsetCoordinator\n- ⏳ Integration tests for multi-folder extraction\n- ⏳ Performance benchmarks\n\n**Performance**: 3 folders × 1k dashboards: 20s → 2s (10x), 10 folders × 500 dashboards: 38s → 3s (12x)\n\n**Design**: See history/multi-folder-sdk-optimization-plan.md for detailed implementation design.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T10:59:21.571339-07:00","updated_at":"2025-12-14T11:17:09.864001-07:00","closed_at":"2025-12-14T11:17:09.864001-07:00","dependencies":[{"issue_id":"lookervault-dil","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:21.571947-07:00","created_by":"daemon"}]}
{"id":"lookervault-e7b","title":"Add folder_ids parsing and validation to extract.py command module","description":"CRITICAL: CLI flags --folder-ids and --recursive are defined in main.py but not implemented in cli/commands/extract.py. Need to: (1) Parse folder_ids from comma-separated string, (2) Validate content types support folder filtering (error on USER, GROUP, ROLE, etc.), (3) Pass folder_ids set to ExtractionConfig, (4) Handle recursive flag. Without this, the feature is non-functional from CLI.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-14T10:59:19.316861-07:00","updated_at":"2025-12-14T11:23:03.166867-07:00","closed_at":"2025-12-14T11:23:03.166867-07:00","dependencies":[{"issue_id":"lookervault-e7b","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:19.317464-07:00","created_by":"daemon"}]}
{"id":"lookervault-e8c","title":"Verify and document Looker SDK folder filtering support across all content types","description":"Verify which Looker SDK methods support folder_id filtering and document the findings. Currently assuming search_dashboards and search_looks support it. Need to check: search_boards, all other content types. Document in CLAUDE.md or create reference guide. This informs optimization decisions.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-14T10:59:17.122245-07:00","updated_at":"2025-12-14T11:25:15.910119-07:00","closed_at":"2025-12-14T11:25:15.910119-07:00","dependencies":[{"issue_id":"lookervault-e8c","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:17.122892-07:00","created_by":"daemon"}]}
{"id":"lookervault-iop","title":"Add folder_ids parsing and validation to restore.py command modules","description":"CRITICAL: CLI flags --folder-ids and --recursive are defined in main.py but not implemented in cli/commands/restore.py and restore_all.py. Need to: (1) Parse folder_ids from comma-separated string, (2) Validate content types support folder filtering, (3) Resolve hierarchy if recursive, (4) Pass folder_ids list to RestorationConfig. Without this, the feature is non-functional from CLI.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-14T10:59:20.402644-07:00","updated_at":"2025-12-14T11:25:15.034211-07:00","closed_at":"2025-12-14T11:25:15.034211-07:00","dependencies":[{"issue_id":"lookervault-iop","depends_on_id":"lookervault-73h","type":"discovered-from","created_at":"2025-12-14T10:59:20.40331-07:00","created_by":"daemon"}]}
{"id":"lookervault-j64","title":"Refactor test suite to reduce coupling to implementation details","description":"Several unit tests in the test suite are too tightly coupled to implementation details rather than testing behavior:\n\n## Issues Identified\n\n1. **ThreadPoolExecutor mocking** - Tests patch specific import paths rather than testing parallel execution behavior\n2. **Internal method mocking** - Tests mock internal implementation details like queue operations\n3. **Mock structure brittleness** - Tests break when refactoring internal structure even when behavior is unchanged\n\n## Examples\n\n- tests/unit/restoration/test_parallel_orchestrator.py - Tests ThreadPoolExecutor creation details instead of testing that work executes in parallel\n- Integration tests provide better coverage of actual behavior (worker coordination, thread safety, checkpointing)\n\n## Recommendation\n\n1. Convert implementation-detail unit tests to behavioral integration tests\n2. Keep unit tests focused on public API contracts and observable behavior\n3. Use integration tests with real dependencies (SQLite, threading) for parallel execution verification\n\n## Benefits\n\n- Tests will be more resilient to refactoring\n- Better coverage of actual system behavior\n- Easier to maintain as implementation evolves\n\n## Priority\n\nLow (p3) - Tests are currently passing after fixes, but future refactoring will be easier with behavior-focused tests.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T13:54:45.774393-07:00","updated_at":"2025-12-14T13:54:57.824696-07:00"}
{"id":"lookervault-jv3","title":"Implement unpack/edit/repack workflow for SQLite content","description":"## Overview\n\nEnable users to unpack SQLite content to JSON files on disk, perform large-scale find/replace operations, and repack for restoration.\n\n**Purpose**: Static analysis and bulk editing without BLOB limitations. Users can use grep, sed, Python scripts, and other tools on plain-text JSON files.\n\n## Feasibility Assessment\n\n✅ **HIGHLY FEASIBLE** - LookerVault architecture is well-suited for this workflow:\n\n### Architecture Strengths\n1. **Clean serialization**: MessagePack (msgspec) → trivial to convert to/from JSON\n2. **Rich metadata**: content_type, folder_id, name, owner, timestamps available for disk organization\n3. **Smart restore logic**: Existing update/create logic handles arbitrary content changes\n4. **Sub-resource handling**: Dashboard elements, filters, layouts fully supported\n\n### Critical Limitation: Immutable Queries\n\n⚠️ **Looker queries are immutable** - no `update_query` API method exists\n- Changing query definitions (SQL, filters) requires `create_query()` + ID remapping\n- Dashboard elements reference `query_id` which must be updated to new query slug\n- See: https://cloud.google.com/looker/docs/reference/looker-api/latest/methods/Query/create_query\n\n## Implementation Phases\n\n### Phase 1: Non-Query Field Editing (2-4 days)\n**Deliverables**:\n- `lookervault unpack --output-dir ./content/` - SQLite BLOB → JSON files\n- `lookervault repack --input-dir ./content/` - JSON files → SQLite BLOB\n- Validation: Schema checks, read-only field filtering, dry-run mode\n- Folder structure: `{content_type}/{folder_id}/{name}-{id}.json`\n\n**Editable Fields** (Phase 1):\n- ✅ Dashboard/Look titles, descriptions\n- ✅ Element titles, subtitles\n- ✅ Filter configurations\n- ✅ Layout positioning\n- ✅ Connection names, database references (string replacement)\n\n**Not Editable** (Phase 1):\n- ❌ Query definitions (SQL, filters, fields) - requires Phase 2\n\n### Phase 2: Query Recreation Logic (4-6 days, future)\n**Deliverables**:\n- Query definition change detection (hashing)\n- Automatic `create_query()` calls for modified queries\n- Old ID → new ID remapping\n- Query deduplication (reuse existing queries with same definition)\n\n## Workflow Example\n\n```bash\n# Unpack to JSON\nlookervault unpack --output-dir ./looker_content/\n\n# Bulk find/replace\ngrep -r \"old_db_name\" ./looker_content/ -l | xargs sed -i 's/old_db_name/new_db_name/g'\n\n# Validate changes\nlookervault repack --validate --dry-run --input-dir ./looker_content/\n\n# Repack to SQLite\nlookervault repack --input-dir ./looker_content/\n\n# Restore to Looker\nlookervault restore bulk dashboards looks\n```\n\n## Risks\n\n- **Low**: JSON conversion, non-query edits, validation logic\n- **Medium**: Query recreation, large-scale find/replace user errors\n- **High**: Cross-instance ID remapping (not planned), query syntax validation\n\n## Recommendation\n\n✅ Implement **Phase 1 immediately** - delivers 80% of value with minimal risk\n⏸ Defer **Phase 2** based on user demand for query modification support","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-14T15:30:31.652286-07:00","updated_at":"2025-12-14T15:30:56.236953-07:00"}
{"id":"lookervault-jv3.1","title":"Phase 1: Implement unpack/repack for non-query fields","description":"Implement basic unpack/repack workflow supporting non-query field edits.\n\n## Tasks\n\n1. **Unpack Command** (4-6 hours):\n   - Read content_items from SQLite\n   - Deserialize msgpack → dict using MsgpackSerializer\n   - Organize by folder: {content_type}/{folder_id}/{name}-{id}.json\n   - Write pretty-printed JSON with __metadata__ header\n   - Preserve original BLOBs for rollback safety\n\n2. **Repack Command** (4-6 hours):\n   - Read JSON files from disk\n   - Validate schema using ContentDeserializer.validate_schema()\n   - Filter read-only fields (50+ fields from deserializer.py)\n   - Serialize dict → msgpack\n   - Update content_items.content_data BLOB\n   - Update updated_at timestamp\n\n3. **Validation Logic** (2-3 hours):\n   - JSON schema validation\n   - Read-only field detection and warnings\n   - Dry-run mode (--dry-run flag)\n\n4. **CLI Integration** (2-3 hours):\n   - Add lookervault unpack command\n   - Add lookervault repack command\n   - Flags: --output-dir, --input-dir, --validate, --dry-run\n\n5. **Testing** (4-6 hours):\n   - Unit tests for serialization/deserialization\n   - Integration tests for unpack → edit → repack → restore\n   - Validation tests for read-only field filtering\n   - Test with 100+ dashboards for performance\n\n## Editable Fields\n\n✅ Titles, descriptions, element titles, filter configs, layouts, connection names, DB refs\n❌ Query definitions (SQL, filters) - deferred to Phase 2\n\n## Acceptance Criteria\n\n- Users can unpack content to organized JSON folder structure\n- Users can perform find/replace with sed/grep/Python\n- Users can repack edited JSON back to SQLite\n- Validation detects read-only field modifications\n- Dry-run mode prevents accidental commits\n- Existing restore commands work with repacked content\n\n## Effort: 2-4 days (1 developer)","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-14T15:31:13.398277-07:00","updated_at":"2025-12-14T15:31:13.398277-07:00","dependencies":[{"issue_id":"lookervault-jv3.1","depends_on_id":"lookervault-jv3","type":"parent-child","created_at":"2025-12-14T15:31:13.398858-07:00","created_by":"daemon"}]}
{"id":"lookervault-jv3.2","title":"Phase 2: Implement query recreation and ID remapping","description":"Add support for editing query definitions with automatic query recreation and ID remapping.\n\n## Background\n\nLooker queries are **immutable** - no update_query API method exists. To \"update\" a query:\n1. Create new query with create_query() (modified definition)\n2. Get new query slug/ID from response\n3. Update dashboard element's query_id field with new ID\n\nSource: https://cloud.google.com/looker/docs/reference/looker-api/latest/methods/Query/create_query\n\n## Tasks\n\n1. **Query Diffing** (6-8 hours):\n   - Implement query definition hashing (SHA256 of SQL + filters + fields)\n   - Compare original vs edited query definitions\n   - Identify modified queries in dashboard elements\n\n2. **Query Creation** (6-8 hours):\n   - Call sdk.create_query() for modified query definitions\n   - Handle API errors and rate limiting with retry logic\n   - Track old_id → new_id mappings in restoration session\n   - Query deduplication: reuse existing queries with same definition\n\n3. **ID Remapping** (4-6 hours):\n   - Update query_id in dashboard elements referencing modified queries\n   - Update JSON files with new query IDs before restoration\n   - Persist ID mappings for audit trail (restoration_sessions table)\n\n4. **Integration** (4-6 hours):\n   - Integrate with existing restoration logic (LookerContentRestorer)\n   - Handle query recreation before dashboard element restoration\n   - Update sub-resource restorer to use remapped IDs\n\n5. **Testing** (6-8 hours):\n   - Unit tests for query diffing and hashing\n   - Integration tests for query recreation workflow\n   - Edge cases: query deduplication, API errors, rollback\n   - Performance test with 1000+ query modifications\n\n## Acceptance Criteria\n\n- Users can edit query SQL/filters/fields in JSON files\n- System automatically creates new queries via create_query()\n- Dashboard elements updated with new query_id references\n- Query deduplication prevents duplicate query creation\n- ID mappings persisted for audit and rollback\n- Restore command handles query recreation transparently\n\n## Editable Fields (Phase 2)\n\n✅ Query SQL, filters, fields, model, view, limit, sorts, pivots, etc.\n\n## Effort: 4-6 days (1 developer)\n\n## Dependencies\n\n- Blocked by: lookervault-jv3.1 (Phase 1 must be completed first)\n- Requires: Phase 1 unpack/repack infrastructure","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-14T15:31:32.62554-07:00","updated_at":"2025-12-14T15:31:45.865195-07:00","closed_at":"2025-12-14T15:31:45.865195-07:00","dependencies":[{"issue_id":"lookervault-jv3.2","depends_on_id":"lookervault-jv3","type":"parent-child","created_at":"2025-12-14T15:31:32.626037-07:00","created_by":"daemon"}]}
{"id":"lookervault-jv3.3","title":"Phase 2: Implement query recreation and ID remapping","description":"Add support for editing query definitions with automatic query recreation and ID remapping.\n\n## Background\n\nLooker queries are **immutable** - no update_query API method exists. To \"update\" a query:\n1. Create new query with create_query() (modified definition)\n2. Get new query slug/ID from response\n3. Update dashboard element's query_id field with new ID\n\nSource: https://cloud.google.com/looker/docs/reference/looker-api/latest/methods/Query/create_query\n\n## Tasks\n\n1. **Query Diffing** (6-8 hours):\n   - Implement query definition hashing (SHA256 of SQL + filters + fields)\n   - Compare original vs edited query definitions\n   - Identify modified queries in dashboard elements\n\n2. **Query Creation** (6-8 hours):\n   - Call sdk.create_query() for modified query definitions\n   - Handle API errors and rate limiting with retry logic\n   - Track old_id → new_id mappings in restoration session\n   - Query deduplication: reuse existing queries with same definition\n\n3. **ID Remapping** (4-6 hours):\n   - Update query_id in dashboard elements referencing modified queries\n   - Update JSON files with new query IDs before restoration\n   - Persist ID mappings for audit trail (restoration_sessions table)\n\n4. **Integration** (4-6 hours):\n   - Integrate with existing restoration logic (LookerContentRestorer)\n   - Handle query recreation before dashboard element restoration\n   - Update sub-resource restorer to use remapped IDs\n\n5. **Testing** (6-8 hours):\n   - Unit tests for query diffing and hashing\n   - Integration tests for query recreation workflow\n   - Edge cases: query deduplication, API errors, rollback\n   - Performance test with 1000+ query modifications\n\n## Acceptance Criteria\n\n- Users can edit query SQL/filters/fields in JSON files\n- System automatically creates new queries via create_query()\n- Dashboard elements updated with new query_id references\n- Query deduplication prevents duplicate query creation\n- ID mappings persisted for audit and rollback\n- Restore command handles query recreation transparently\n\n## Editable Fields (Phase 2)\n\n✅ Query SQL, filters, fields, model, view, limit, sorts, pivots, etc.\n\n## Effort: 4-6 days (1 developer)","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-14T15:31:56.438414-07:00","updated_at":"2025-12-14T15:32:19.925917-07:00","closed_at":"2025-12-14T15:32:19.925917-07:00","dependencies":[{"issue_id":"lookervault-jv3.3","depends_on_id":"lookervault-jv3","type":"parent-child","created_at":"2025-12-14T15:31:56.439059-07:00","created_by":"daemon"}]}
{"id":"lookervault-jv3.4","title":"Phase 2: Implement query recreation and ID remapping","description":"Add support for editing query definitions with automatic query recreation and ID remapping.\n\n## Background\n\nLooker queries are **immutable** - no update_query API method exists. To \"update\" a query:\n1. Create new query with create_query() (modified definition)\n2. Get new query slug/ID from response\n3. Update dashboard element's query_id field with new ID\n\nSource: https://cloud.google.com/looker/docs/reference/looker-api/latest/methods/Query/create_query\n\n## Tasks\n\n1. **Query Diffing** (6-8 hours):\n   - Implement query definition hashing (SHA256 of SQL + filters + fields)\n   - Compare original vs edited query definitions\n   - Identify modified queries in dashboard elements\n\n2. **Query Creation** (6-8 hours):\n   - Call sdk.create_query() for modified query definitions\n   - Handle API errors and rate limiting with retry logic\n   - Track old_id → new_id mappings in restoration session\n   - Query deduplication: reuse existing queries with same definition\n\n3. **ID Remapping** (4-6 hours):\n   - Update query_id in dashboard elements referencing modified queries\n   - Update JSON files with new query IDs before restoration\n   - Persist ID mappings for audit trail (restoration_sessions table)\n\n4. **Integration** (4-6 hours):\n   - Integrate with existing restoration logic (LookerContentRestorer)\n   - Handle query recreation before dashboard element restoration\n   - Update sub-resource restorer to use remapped IDs\n\n5. **Testing** (6-8 hours):\n   - Unit tests for query diffing and hashing\n   - Integration tests for query recreation workflow\n   - Edge cases: query deduplication, API errors, rollback\n   - Performance test with 1000+ query modifications\n\n## Acceptance Criteria\n\n- Users can edit query SQL/filters/fields in JSON files\n- System automatically creates new queries via create_query()\n- Dashboard elements updated with new query_id references\n- Query deduplication prevents duplicate query creation\n- ID mappings persisted for audit and rollback\n- Restore command handles query recreation transparently\n\n## Editable Fields (Phase 2)\n\n✅ Query SQL, filters, fields, model, view, limit, sorts, pivots, etc.\n\n## Effort: 4-6 days (1 developer)","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-14T15:32:06.327413-07:00","updated_at":"2025-12-14T15:32:06.327413-07:00","dependencies":[{"issue_id":"lookervault-jv3.4","depends_on_id":"lookervault-jv3","type":"parent-child","created_at":"2025-12-14T15:32:06.327942-07:00","created_by":"daemon"},{"issue_id":"lookervault-jv3.4","depends_on_id":"lookervault-jv3.1","type":"blocks","created_at":"2025-12-14T15:32:06.328527-07:00","created_by":"daemon"}]}
{"id":"lookervault-yos","title":"Make all SQLite write operations idempotent (upsert)","description":"## Problem\n\nCurrently when running multiple extractions, the system appends content instead of performing upsert operations. This breaks the most common workflow: pull snapshot → run partial extract to update → upload updated snapshot.\n\n## Current State Analysis\n\n**Already Upsert (✅)**:\n- save_content(): Uses INSERT ... ON CONFLICT(id) DO UPDATE SET\n- save_id_mapping(): Uses INSERT ... ON CONFLICT(...) DO UPDATE SET\n\n**Plain INSERT (❌ - Needs Fix)**:\n- save_checkpoint(): Lines 601-655\n- create_session(): Lines 758-792\n- save_dead_letter_item(): Lines 1158-1214\n- save_restoration_checkpoint(): Lines 1612-1666\n- create_restoration_session(): Lines 1769-1822\n\n## Impact\n\nWithout upsert operations:\n- Running extract twice creates duplicate checkpoint entries or fails on PK violation\n- Resuming with same session_id fails instead of updating existing session\n- DLQ items can be duplicated if retry logic re-saves same failure\n- Cannot safely re-run partial extractions to update snapshots\n\n## Requirements\n\nALL write operations must be idempotent:\n1. Running operation twice with same data = same final state\n2. No errors on re-run (no PK violations)\n3. Updates existing records instead of creating duplicates\n4. Safe for the workflow: pull → partial extract → upload\n\n## Acceptance Criteria\n\n- [ ] save_checkpoint() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] create_session() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] save_dead_letter_item() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] save_restoration_checkpoint() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] create_restoration_session() uses INSERT ... ON CONFLICT DO UPDATE\n- [ ] All operations tested with duplicate calls (verify idempotency)\n- [ ] No database schema changes required (current PKs/constraints sufficient)","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-14T12:15:10.356229-07:00","updated_at":"2025-12-14T13:00:28.094881-07:00","closed_at":"2025-12-14T13:00:28.094881-07:00"}

# Feature Specification: Looker Content Restoration

**Feature Branch**: `004-looker-restoration`
**Created**: 2025-12-13
**Status**: Draft
**Input**: User description: "Now's the time for the most important feature. We need to be able to read the data inside of this Looker DB sqlite instance, deserialize it back into our domain objects (or into the Looker SDK domain objects, whatever we're using), and then be able to issue patch requests (ideally like update/patch requests) to the Looker API through the SDK in order to update objects in place and restore them to the state which they were in before. If an object does not exist, a specific ID does not exist, then we can create the object. That will generate a new ID, and we should possibly reflect that bi-directionally, but ideally we're oriented mostly towards patch requests. So there is that. We should be able to update objects in parallel, so we'll need a similar mechanism for parallelism. Very robust error and exception handling, dead letter queue type behavior. Lastly, it's highly likely the order in which we restore things matters a lot more than when we were reading things. If, i.e., certain IDs or things are expected to exist in a certain state in order for other things which depend on them to be correctly updated, that needs to be respected. We should try to respect some sort of ontology or whatever that we can surmise Looker likely respects without necessarily replicating Looker's exact relational model in how we insert things, but do some research and make sure this is a consideration. The interface for this should be quite granular, and I will likely run an integration test on a single object, like a single dashboard for example. Just because this is going to be running on a production instance."

## User Scenarios & Testing *(mandatory)*

### User Story 1 - Single Object Restoration for Testing (Priority: P1)

An administrator needs to restore a single dashboard from the SQLite backup to a production Looker instance to verify restoration works correctly before attempting bulk operations.

**Why this priority**: This is the minimum viable capability needed to safely test restoration on production. It provides the foundation for all other restoration scenarios and allows incremental verification of the restoration process.

**Independent Test**: Can be fully tested by selecting a single dashboard from SQLite, running the restore command with that dashboard's ID, and verifying the dashboard appears correctly in Looker with all its properties intact.

**Acceptance Scenarios**:

1. **Given** a dashboard exists in the SQLite backup but not in Looker, **When** the administrator runs restore for that dashboard ID, **Then** a new dashboard is created in Looker with matching properties and the system records the new ID generated by Looker
2. **Given** a dashboard exists in both SQLite and Looker with different content, **When** the administrator runs restore for that dashboard ID, **Then** the existing Looker dashboard is updated to match the SQLite backup without changing its ID
3. **Given** a dashboard restoration fails due to missing dependencies, **When** the system encounters the error, **Then** the error is logged with specific details about which dependencies are missing and the dashboard remains in a safe state

---

### User Story 2 - Dependency-Aware Bulk Restoration (Priority: P2)

An administrator needs to restore multiple content items (dashboards, looks, folders, users, groups) from SQLite backup while respecting dependencies between objects (e.g., dashboards depend on looks, looks depend on explores, content depends on folders, permissions depend on users and groups).

**Why this priority**: This delivers the core business value of the feature - recovering from data loss or migrating content between instances. It builds on P1 by adding dependency ordering and bulk processing.

**Independent Test**: Can be tested by selecting a set of related content items (e.g., a folder, dashboards in that folder, and users who own them), running bulk restore, and verifying all items are restored in the correct order with relationships intact.

**Acceptance Scenarios**:

1. **Given** multiple content items with dependencies exist in SQLite, **When** bulk restore is initiated, **Then** items are restored in dependency order (users → groups → folders → models → explores → looks → dashboards → boards)
2. **Given** a content item depends on another item that exists in Looker but not in SQLite, **When** restore is attempted, **Then** the system uses the existing Looker item and continues restoration without error
3. **Given** bulk restoration is processing 1000 items, **When** a network error occurs after 500 items, **Then** the system records successful completions in a checkpoint and allows resume from item 501

---

### User Story 3 - Parallel Restoration with Error Recovery (Priority: P2)

An administrator needs to restore tens of thousands of content items efficiently using parallel workers while handling errors gracefully through retry logic and dead letter queue mechanisms.

**Why this priority**: This addresses performance and reliability for large-scale restorations. It leverages the existing parallel extraction architecture and ensures production safety through robust error handling.

**Independent Test**: Can be tested by initiating parallel restore of 10,000+ items with simulated transient errors (rate limits, network issues) and verifying throughput meets targets (100+ items/second), errors are retried appropriately, and unrecoverable failures are captured in dead letter queue.

**Acceptance Scenarios**:

1. **Given** 10,000 content items need restoration with 8 workers configured, **When** parallel restore runs, **Then** system achieves minimum 100 items restored per second with automatic rate limiting
2. **Given** API rate limit (429) is encountered during parallel restore, **When** the rate limiter detects the 429 response, **Then** all workers automatically slow down and gradually recover after sustained success
3. **Given** a content item fails restoration after maximum retry attempts, **When** retries are exhausted, **Then** the item is moved to a dead letter queue with full error context and restoration continues for remaining items
4. **Given** parallel restoration is interrupted mid-process, **When** restore is restarted with resume flag, **Then** system skips already-completed items and continues from the last checkpoint

---

### User Story 4 - ID Mapping for Cross-Instance Migration (Priority: P3)

An administrator needs to restore content from one Looker instance to a different Looker instance where IDs will necessarily differ, requiring bidirectional mapping between source IDs and destination IDs.

**Why this priority**: This enables migration scenarios between different Looker instances (dev → prod, backup instance → new instance). It's lower priority than basic restore because same-instance restoration works without ID mapping.

**Independent Test**: Can be tested by restoring content from Instance A's backup to Instance B, verifying all content is created with new IDs, and checking that a mapping table records old ID → new ID relationships for future reference.

**Acceptance Scenarios**:

1. **Given** content from Instance A is being restored to Instance B, **When** new objects are created in Instance B, **Then** the system maintains a mapping table of source_id → destination_id for each content type
2. **Given** a dashboard references a look by ID and both are being migrated, **When** the look is created first with a new ID in the destination, **Then** the dashboard's reference to the look is updated to use the new destination ID
3. **Given** ID mapping exists for previously migrated content, **When** incremental restore is run, **Then** the system uses existing mappings to update rather than duplicate content

---

### Edge Cases

- What happens when a dashboard references a deleted look during restoration? (System should log warning, attempt to restore the look if it exists in SQLite, or skip the reference if not recoverable)
- How does the system handle circular dependencies between content items? (Use topological sort to detect cycles, break cycles by null-ing forward references, then update in second pass)
- What happens when Looker API returns validation errors for content that was previously valid? (Log validation error with full context, move to dead letter queue, continue with other items)
- How does the system handle content that has been modified in Looker since backup? (Default behavior is to overwrite with backup; provide `--skip-if-modified` flag to preserve Looker changes)
- What happens when SQLite backup contains content types not supported by the destination Looker version? (Detect API version compatibility, skip unsupported types, log clear warnings)
- How does the system handle extremely large content items (e.g., dashboards with hundreds of widgets)? (Validate content size before API call, split into multiple requests if API limits require, or log oversized items for manual review)

## Requirements *(mandatory)*

### Functional Requirements

#### Deserialization & Data Access

- **FR-001**: System MUST read content items from SQLite database by content type and ID
- **FR-002**: System MUST deserialize binary content_data blobs back into Looker SDK domain objects
- **FR-003**: System MUST handle content items with missing or corrupted data by logging errors and skipping the item
- **FR-004**: System MUST provide filtering capabilities to select specific content items for restoration (by ID, content type, date range, owner)

#### API Operations & Update Logic

- **FR-005**: System MUST attempt to update existing Looker objects using PATCH/PUT operations when an object with matching ID exists in destination
- **FR-006**: System MUST create new Looker objects using POST operations when an object ID does not exist in destination
- **FR-007**: System MUST preserve original object IDs when updating existing objects in the same Looker instance
- **FR-008**: System MUST record newly generated IDs when creating objects in a different Looker instance
- **FR-009**: System MUST validate content against Looker API schema before attempting restoration
- **FR-010**: System MUST support dry-run mode that simulates restoration without making actual API calls

#### Dependency Ordering

- **FR-011**: System MUST restore content types in dependency order: Users → Groups → Roles → Permission Sets → Folders → LookML Models → Explores → Looks → Dashboards → Boards → Scheduled Plans
- **FR-012**: System MUST detect when a content item references another item that needs to be restored first
- **FR-013**: System MUST handle forward references by deferring restoration until dependencies are satisfied or by using placeholder values updated in a second pass
- **FR-014**: System MUST support partial restoration of a dependency subtree (e.g., restore a dashboard and all its dependent looks/explores)

#### Parallel Execution

- **FR-015**: System MUST support parallel restoration using configurable worker threads (default: 8 workers)
- **FR-016**: System MUST coordinate rate limiting across all workers to respect Looker API limits
- **FR-017**: System MUST use thread-safe operations when updating shared state (checkpoints, metrics, dead letter queue)
- **FR-018**: System MUST prevent duplicate restoration attempts when multiple workers process the same content type

#### Error Handling & Recovery

- **FR-019**: System MUST retry failed API calls using exponential backoff for transient errors (network issues, rate limits, temporary unavailability)
- **FR-020**: System MUST move items to a dead letter queue after exhausting retry attempts (configurable max retries, default: 5)
- **FR-021**: System MUST record detailed error context in dead letter queue entries: content ID, content type, error message, stack trace, timestamp, retry count
- **FR-022**: System MUST continue restoration of remaining items after encountering unrecoverable errors for individual items
- **FR-023**: System MUST save progress checkpoints at regular intervals (default: every 100 items) to enable resume capability
- **FR-024**: System MUST support resume operation that skips already-restored items and continues from last checkpoint
- **FR-025**: System MUST detect and handle API validation errors by logging full validation details and moving items to dead letter queue

#### Granular Interface

- **FR-026**: System MUST provide CLI command to restore a single content item by type and ID
- **FR-027**: System MUST provide CLI command to restore multiple content items filtered by criteria
- **FR-028**: System MUST provide CLI command to restore all content of a specific type
- **FR-029**: System MUST display restoration progress in real-time (items processed, success count, error count, throughput)
- **FR-030**: System MUST generate restoration summary report upon completion (total items, successful, failed, duration, average throughput)

#### ID Mapping & Cross-Instance Support

- **FR-031**: System MUST maintain a persistent mapping table of source_id → destination_id for created objects
- **FR-032**: System MUST update references within content to use destination IDs when mapping exists
- **FR-033**: System MUST support querying ID mappings to determine if content has been migrated
- **FR-034**: System MUST handle scenarios where source and destination are the same instance (no ID remapping needed)

### Key Entities

- **RestorationSession**: Represents a single restoration operation with session ID, start/end timestamps, configuration, status, and summary statistics
- **RestorationCheckpoint**: Tracks progress within a restoration session including last processed item, items completed, items failed, and checkpoint data for resume
- **DeadLetterItem**: Represents a content item that failed restoration after all retries, including original content, error details, retry history, and timestamp
- **IDMapping**: Maps source content IDs to destination content IDs for cross-instance migration, keyed by (source_instance, content_type, source_id) → destination_id
- **DependencyGraph**: Represents relationships between content items to determine restoration order (implementation detail, not persisted)
- **RestorationTask**: Represents a single content item to be restored with its priority, dependencies, and current status

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: Administrators can successfully restore a single dashboard from SQLite to Looker in under 10 seconds including dependency validation
- **SC-002**: System achieves minimum throughput of 100 content items restored per second with 8 parallel workers for large datasets (10,000+ items)
- **SC-003**: System automatically recovers from API rate limiting (HTTP 429) with zero administrator intervention and resumes at full throughput within 2 minutes
- **SC-004**: 99% of transient errors (rate limits, network timeouts) are successfully retried without moving items to dead letter queue
- **SC-005**: System can resume interrupted restoration operations and skip already-completed items with 100% accuracy (zero duplicates)
- **SC-006**: Administrators can test restoration on a single object and receive clear success/failure feedback within 30 seconds
- **SC-007**: Dead letter queue captures 100% of unrecoverable failures with sufficient context to debug and manually retry
- **SC-008**: Restoration of 50,000 content items completes in under 10 minutes with 8 workers (average 83 items/second minimum)

### Assumptions

- The Looker SDK provides PATCH/PUT methods for updating existing content objects
- The Looker SDK provides POST methods for creating new content objects
- Content stored in SQLite is valid at the time of backup (invalid content is edge case, not primary concern)
- The destination Looker instance is accessible and authenticated using the same credential model as extraction
- API rate limits are similar to extraction limits and can be handled with the same adaptive rate limiting mechanism
- The SQLite schema includes all necessary metadata to deserialize content back into Looker SDK objects
- Content types have a relatively stable dependency order that can be predetermined (no dynamic dependency analysis of individual item content)
- The same thread-safe SQLite patterns used in extraction can be reused for restoration (thread-local connections, BEGIN IMMEDIATE transactions)
- Looker API validation errors are rare for content that was previously valid and can be treated as exceptional cases
- The Looker SDK serialization format (likely JSON) is stable between extraction and restoration operations
